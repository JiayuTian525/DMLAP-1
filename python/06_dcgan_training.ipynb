{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dcgan\n",
        "=====\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[https://keras.io/examples/generative/dcgan_overriding_train_step/](https://keras.io/examples/generative/dcgan_overriding_train_step/)\n",
        "\n",
        "To run this you will need gdown\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (4.6.4)\n",
            "Requirement already satisfied: tqdm in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: requests[socks] in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from gdown) (2.28.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from gdown) (4.11.1)\n",
            "Requirement already satisfied: filelock in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: six in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.11)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import (Input, Reshape, Dropout, Dense,\n",
        "                                     Flatten, BatchNormalization,\n",
        "                                     Activation, ZeroPadding2D, LeakyReLU,\n",
        "                                     UpSampling2D, Conv2D)\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gdown\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Celeb data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we will use the Celeb dataset. We will resize images to a size of `64x64`.\n",
        "First download the dataset (only need to do this once, then it will throw an error but don&rsquo;t worry):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileExistsError",
          "evalue": "[Errno 17] File exists: 'datasets/celeba_gan'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/sr/zs7syfx13zzfn32_m3hpw17c0000gn/T/ipykernel_64412/3364950564.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/celeba_gan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"datasets/celeba_gan/data.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/miniconda3/lib/python3.10/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'datasets/celeba_gan'"
          ]
        }
      ],
      "source": [
        "os.makedirs(\"datasets/celeba_gan\", exist_ok=False)\n",
        "\n",
        "url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n",
        "output = \"datasets/celeba_gan/data.zip\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "with ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n",
        "    zipobj.extractall(\"datasets/celeba_gan\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then convert this to a Tensorflow dataset. Because we expect to be training on our laptops, we will reduce the size of the training set. This is not ideal for GANs, but it will still produce reasonable results. Here we also scale the inputs to the `[-1, 1]` range and make sure the dataset is subdivided into batches of the desired size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 202599 files belonging to 1 classes.\n",
            "WARNING:tensorflow:From /Users/colormotor/opt/miniconda3/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "image_size = 64 # images are square\n",
        "image_channels = 3 # 3 RGB 1 Grayscale\n",
        "image_shape = (image_size, image_size, image_channels)\n",
        "dataset_size = 200\n",
        "batch_size = 32\n",
        "\n",
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    \"datasets/celeba_gan\", label_mode=None, image_size=(image_size, image_size), batch_size=None)\n",
        "\n",
        "dataset = dataset.take(dataset_size)\n",
        "dataset = dataset.map(lambda x: x / 127.5 - 1.0)\n",
        "dataset = dataset.batch(batch_size) # We create batch here since \"take\" would unbatch it.."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let&rsquo;s see one random instance from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for x in dataset:\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow((x.numpy() * 127.5 + 127.5).astype(\"int32\")[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create generator\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At this staget we need to construct our generator. There are many implementations out there, this is one that works reasonably well for our use case and it is adapted from [here](https://github.com/Kaustubh1Verma/Art-using-GANs/blob/ff41eeb5099d2aa3976ed1f051596d14015548d5/DCGAN/DCGAN.py).\n",
        "For GAN models it is [recommended](https://machinelearningmastery.com/how-to-code-generative-adversarial-network-hacks/) to initialize the layers with normally distributed (Gaussian) values and standard deviation of 0.02. The following function is built to enable training on different image sizes, but we recommend sticking with the `64x64` image size:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 512)               51712     \n",
            "                                                                 \n",
            " reshape_5 (Reshape)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_45 (Bat  (None, 2, 2, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " up_sampling2d_25 (UpSamplin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 4, 4, 1024)        1180672   \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 4, 4, 1024)        0         \n",
            "                                                                 \n",
            " batch_normalization_46 (Bat  (None, 4, 4, 1024)       4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " up_sampling2d_26 (UpSamplin  (None, 8, 8, 1024)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 8, 8, 512)         4719104   \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " batch_normalization_47 (Bat  (None, 8, 8, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " up_sampling2d_27 (UpSamplin  (None, 16, 16, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 16, 16, 256)       1179904   \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " batch_normalization_48 (Bat  (None, 16, 16, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " up_sampling2d_28 (UpSamplin  (None, 32, 32, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 32, 32, 128)       295040    \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_49 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " up_sampling2d_29 (UpSamplin  (None, 64, 64, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 64, 64, 64)        73792     \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_50 (Bat  (None, 64, 64, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 64, 64, 32)        18464     \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_51 (Bat  (None, 64, 64, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 64, 64, 3)         867       \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,528,131\n",
            "Trainable params: 7,523,843\n",
            "Non-trainable params: 4,288\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "kernel_size = 3\n",
        "latent_dim = 100 # The size of the latent space\n",
        "\n",
        "init = lambda: tf.keras.initializers.RandomNormal(stddev=0.02)\n",
        "\n",
        "def build_generator():\n",
        "    # From https://github.com/Kaustubh1Verma/Art-using-GANs/blob/ff41eeb5099d2aa3976ed1f051596d14015548d5/DCGAN/DCGAN.py\n",
        "    # This block of code can be a little daunting, but essentially it automatically calculates the required starting\n",
        "    # array size that will be correctly upscaled to our desired image size.\n",
        "    #\n",
        "    # We have 5 Upsample2D layers which each double the images width and height, so we can determine the starting\n",
        "    # x size by taking (x / 2^upsample_count) So for our target image size, 256x192, we do the following:\n",
        "    # x = (192 / 2^5), y = (256 / 2^5) [x and y are reversed within the model]\n",
        "    # We also need a 3rd dimension which is chosen relatively arbitrarily, in this case it's 64.\n",
        "    model = Sequential()\n",
        "    upsample_layers = 5\n",
        "    starting_filters = 128\n",
        "    start_size = image_size // (2 ** upsample_layers)\n",
        "    model.add(Dense(starting_filters * start_size * start_size, activation=\"relu\", input_dim=latent_dim))\n",
        "    model.add(Reshape((start_size, start_size, starting_filters)))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())  # 6x8 -> 12x16\n",
        "    model.add(Conv2D(1024, kernel_size=kernel_size, padding=\"same\", kernel_initializer=init()))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())  # 12x16 -> 24x32\n",
        "    model.add(Conv2D(512, kernel_size=kernel_size, padding=\"same\", kernel_initializer=init()))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())  # 24x32 -> 48x64\n",
        "    model.add(Conv2D(256, kernel_size=kernel_size, padding=\"same\", kernel_initializer=init()))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())  # 48x64 -> 96x128\n",
        "    model.add(Conv2D(128, kernel_size=kernel_size, padding=\"same\", kernel_initializer=init()))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(UpSampling2D())  # 96x128 -> 192x256\n",
        "    model.add(Conv2D(64, kernel_size=kernel_size, padding=\"same\", kernel_initializer=init()))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=kernel_size, padding=\"same\", kernel_initializer=init()))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Conv2D(image_channels, kernel_size=kernel_size, padding=\"same\", kernel_initializer=init()))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)\n",
        "\n",
        "generator = build_generator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let&rsquo;s see it&rsquo;s output before training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGfCAYAAAD22G0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjxklEQVR4nO29eZCd1X3n/bv71vfe3u/tllrdLam1g9ACQgJb2IASxvYbhoqXQDyk5q0pMDiG8cyLLagZi5Qj2aSKUVIQpUQyWLwOUd4Zm4SMF6TYIGwUjBAIhHapV6n79n73/d7z/qGh7db5HkfNMk+r9f1UdRX87tF5zvY85z59vv392ZRSSgghhBALsFvdAEIIIVcv3IQIIYRYBjchQgghlsFNiBBCiGVwEyKEEGIZ3IQIIYRYBjchQgghlsFNiBBCiGVwEyKEEGIZ3IQIIYRYhvPjqvgv//Iv5c/+7M9kaGhIVq5cKTt37pRPfOIT/+q/q1arMjg4KMFgUGw228fVPEIIIR8TSilJpVLS2toqdvu/8q6jPgb27t2rXC6XeuaZZ9Tx48fVQw89pAKBgOrr6/tX/+3AwIASEf7whz/84c8V/jMwMPCvPvNtSn30BqYbNmyQtWvXyq5du6Ziy5cvlzvvvFN27NjxW/9tIpGQ2tpaueYL/0UcLu+0zypu/G/SC/SYcuCyviH8dmUv4/L5BlC2hMsGB6owXgrga7qTeOiLIb28O43LVly47kIdjpcCoGwDbrfy4HjDvASMJ9MefM24V4vZa/AgqjieZPeEYUINqzcwpH9gmoeq4fcBjqIhXtDrrrhx3TY8hJJtxQ13pnE9pvWMcBRwvOzHcVdKjwWGccNn2s90Ky5fAUulVFeBZZXDMMkuHHck9Amteg0NNISVH7dFFO6P06+v50AAT0TFUMd1zRdgvM6VhfFEyafFfA78IOvL1sF4jcuwWADvDrbAeHFCb0c1n5fBrdslHo9LOBz+rfV+5L+OKxaLcvjwYfnmN785Lb5lyxY5ePCgVr5QKEih8OuBSKUu3hEOl1cc7kseXoZNyK4/44w3rcNj2IQMb4wOcLMYy7rxiq4ablyn4SZCN7rDUFYMdZv6WUX98c1sE3L48zBur4KJEBF7AWxCfjxBqoAn2eGd2SbkcOsfVA1jYjNtQobfBjvQ9zZT3YZnmd1reICWPoJNyBBXeHrgZutwGZ7OM9yETOtQQFsqvo9mE7IXwIQa1rhxEzK0xbQJofXsMGz6pjrcNXjte1z4C5u7pJd3Gxaty4brdpmeKwCH33B/5wwLS+SyjlQ+cmHC2NiYVCoViUQi0+KRSERisZhWfseOHRIOh6d+2traPuomEUIImaV8bOq4S3dApRTcFbdu3SqJRGLqZ2Bg4ONqEiGEkFnGR/7ruMbGRnE4HNpbz8jIiPZ2JCLi8XjE49F/RxSIlcTpnP6KW3HjPbP+uP77hIkV+u8pRUSKhl9PujL4tdSd0DfOXMTw+/w8jqfbcLvzDZd/PuUfM/zKzPC7l/Ra/Cszf43+O+D/a8FpWPbQKDhsE5FKFfdHGeKhFv3Qwe/BBy7xM/oaERGp+PDYlgN4XPwxvS3J1fj333bDr54cA/jXDL5hMG+G32rkojM7ci00Xv482wuGc78grtuVMpzPgG4O34zbbTOchzpb8LlFKWb4nRT4FZstbDiEm8BnjatW9sJ4Evz69/xYLSwbqU/C+NAwLq9y+JFZBvHO+eOwrNdwbmMiV8W/Sjs+qd8rWcOvs03U+XMw3ne+UYt5wLNDRMSZ1BdnNX/5vz/+yN+E3G63rFu3Tvbv3z8tvn//ftm0adNHfTlCCCFXMB/L3wl9/etfly9/+cuyfv162bhxo+zevVv6+/vl/vvv/zguRwgh5ArlY9mEvvjFL8r4+Lj8yZ/8iQwNDcmqVavkxz/+sbS3t38clyOEEHKF8rE5JjzwwAPywAMPfFzVE0IImQPQO44QQohlfGxvQh+WYtAhVdd0hUW+Fu+ZVbeunnGnsLrHkzDF8R+nFWp1lUfG8KdMmShWhDixcAi6F4hgZwhbBbc7MISVNpl3sTpQRI//4+gaWLL2HReuwvD3ZwZDAlFOXSGVwoInib6NFVLZCG5LIYzHPDigy7gmN+ExVBWDyqzRoGJS4C/yPYb5GcBr1uSWUfYZ1jjovknpGeo2qTfxGi/59WsqGx5X7ziuuzBcA+PNp/A1XUl9bPONeFH4h/GaGDnUAeMK/ClIneFJF49i9V7DsEHpugCvlfwCvY1Hji6EZVsWjcL4WAKPod+L+5/sqdVi7jheP6UgVl3m5uH7auVC3b2hP65fT0QkA/7gtWp4XiH4JkQIIcQyuAkRQgixDG5ChBBCLIObECGEEMuYtcKEss8u6hKbnlyTwTG6ePl7aWIxjtvK+IAu2AcO2Gz40M1k/ZPqMDgj23H5mj49FuhLw7LlID7MdRlSPyDBhjOD+25wCzHGg3348DO+RJ8fF3ZLkYkVuHJT+oxsi8FeBpzkOwxuxB0RbK8y8Np8GHfkgJVTyJDGw2ChYy8b1jJIEyEi0HnZgZ2ZjIIXR9FwqA7soxqPYVFGySCcMFlQ+YZwI0thfZ6V4TZOtuM1ProJt9E9rD/WKn48rtVGbEVTDONrVg3O8va4fk0FnNxFRO6c/w6M/8y9DMZ7x+ph3JXQB6xQb3D/NlDJ4vttMBnSYtksHhMbEPagmAm+CRFCCLEMbkKEEEIsg5sQIYQQy+AmRAghxDK4CRFCCLGMWauOcxSUOKvT1SWeSUPZoq5CcSdNKhHcZQ+wERHBliaOvEHtZhCEhM9gRY0ri9UzJb9eUbEe2/B4e7Gyq87dAOMVj94fk/LMmcft9o5gRVHFj8d2crmuqjElAKw/jtVUzgROvjW+tg7GbVW9/nIet+/c+SYYn38Yr6Fku16P8yy2ubEb8rR5J/HYmhIguoHdlH8Y121ah9lmXHeqS1/7ZR8eK5fBgqriNdj5GKx4kA1VIYwb7p0wWCJ1Y1VnzXl9bANDeJHnGrE6rFALw2Kr4jZmm/V4oQHP8c9GsAruQgL7MLU34Aff2YVgHV7AiRhNJjoVw2KZLOvqOF89vgclqddRMSRcRPBNiBBCiGVwEyKEEGIZ3IQIIYRYBjchQgghlsFNiBBCiGXMWnVcxW0TcU9XWKQ6cNnJOl3F5Ilh5YwP55OS9Dw8FDYgcPEZVElVg1dU7VmsJlNOg8rOAXzPClippbxY3ZOaj+PIfy/fjNvd8SKWdhUasOIp12BI6pfRY95JfE1HzqBiasMmbJkWkwebHgucxmNiM+Suy0RxG3NgvGr6cR1Og7+bfxj3M7UAj202ovczMGRIXpczJO8ziJscWf27qH/k8pOSXQTPg78HmwTaU/qisFUisKyvP4HrHsZrwn1eV5NVzvbAsrVdOPFcdjFWlzoKWPFWdehry17B3/FPn8CehCZOj2AzQO+Q/pzwD+J588ZxPLYRX1MBb8PcJFboBsBjQhlUoQi+CRFCCLEMbkKEEEIsg5sQIYQQy+AmRAghxDK4CRFCCLGMWauOK4Zt4rhEHedYmIJlyyldUeSZwPWChJsiYkyWKg6g8sg3GhQoY1ghlItgVVbgPJYrJRbq/k+JhX5YtuEY7tD4bViWVU3r5ZcvOw/L9iY7YNyxLg7jdX6D/KqsLzO3G8tnxv6+FcaRSlFEJDcfqwbtIPtppcbghRfDt0Hz716A8bVB3a+v3g0kgCLyxlg7jMdengfj2cUGWVFe/75YdWE1YqkWr0//efyd0waEekiN99vILcTtDvVhPzRXUld8ZaJ4LbsTWJVlL+H5LCzQM5F6gZegiEjiWuwbOLEMj22w35Ch1aWPV4MhO61nAtdtyiyr7Lg8wqSCs5cN2aBT+KLebv2eKNXga7rAY9nkmYjgmxAhhBDL4CZECCHEMrgJEUIIsQxuQoQQQixj1goTCrUijkv0BoW0IUFWXj+48xgO6FxZfJhpsjop1ej7dP1xfODoe6sPt8+DhQnVCZysKrD4Wi1WAQefIjjpnoiI5zQ+zK0/rh/ku1fgw31TorL8ALZLqVuKhQmjfXriuckkPmztOGNIajeJ6w6ex6el6JB7dB0eq9ISnKmtakj45bHr828q29uHD75lkeHktmhIajepj5dvFF+z4sV1OA0J6Wyg7dkWQyLGFL6mzYHLTyzFa7/pXb18qh3X7cxjUU7oLBYqVbz6WCk7rjt0Mm64pp7UTUTEZUh+mWvW++mOY2smdxDPT7oVx6t4CCV8Th9DUzLPihf3P4C1N5LXtR1SDBvUWzaU1A4XRfBNiBBCiGVwEyKEEGIZ3IQIIYRYBjchQgghlsFNiBBCiGXMWnWcvSiiCVoMyiFk0VJ/PI0rVljhkerEiaMKIaQqMSTAW70Axou1uHzoFawEyzXo/azoTj4iIuIoYtULstIQESmE9LpjGax2s1UM1i0hrBC6MFqL6wno5StVg9qvBo9VoRarlTLRy7dAcWbwNZesxlkKT73eAeN9LXrCsxXtQ7CsdwBLm0pBrCarBLG6qVivx/0X8FgFLhiUUMP4mr4RXak3fANecBWD7ZXK4bYowxNm9Fq9okIE970wjO/7iWvwmkAkOqMwbkqUicZbRKSmB6tOXSnwXLHhuTcpcX1jOG6yrKr71aAerODCqga3uxBshHEnECQ685dv5WSjOo4QQsiVADchQgghlsFNiBBCiGVwEyKEEGIZ3IQIIYRYxqxVx5VrlFQv8S5zpPGeiRIzxZdgtVv4HDbQCvbiuHKAegwWSpkWrIaxGRR5qhX7ivnGdIVLosugEFqFFStVF1bJIC+8TzcNwLI/mlcL4+sWYY+8a0JArSMiLpuuNNrbvRaWTXToPnMiIsqQ1yvXjMfWM6GPixPnnZPeCWCUJSLKhete0qar6UzeccUwngdHK15vi5v1hHkiIoWKfquOdePEeMF+g0LKIG5yZHWPM38M+zQmFuM6XIZEbb5hk4ejHvfEDUn3sBhT8vW4Q/4Rvf/BAezjVvbhfjoMaj/TGiqG9bbYS7g/2RbcbjtuovgNY5hY36LFfKPYk1ABfzcREWfBoNQb0eO+cawYTLfqY1UpGh6SAL4JEUIIsQxuQoQQQiyDmxAhhBDL4CZECCHEMrgJEUIIsYwZq+NeffVV+bM/+zM5fPiwDA0NyQsvvCB33nnn1OdKKXn88cdl9+7dMjk5KRs2bJCnn35aVq5cOaPrVN0iconYrFKPZTLBHl2VFurFvmyOM+fxBaMGpdqoXnfVhffuYggrhDxx3G57CmcLVXZdIabsWG1Sg4VqUvEYlDmtej2nks24EgPnU7UwfnP9WRg/OLlIb8e5MCzbesEwVga1TXIx7ifMJGlQh61owIq0s2/hNp59q02/Xg1WpNWdwRfNT+CMsKfmY8825ONXP4HHpOLB18w2GxR8NXpb8o24bKEJz4/N4AXoKFz+99xS0KDgMthAmjKOVh1AqVbG81PbjSVpE0uxSZ69bFBjgiTJpv54DR5xpnnLN+B42aePrb2M251twM8ml8HHzp3Rx8uUnbVUgzKrXr7P3IzfhDKZjKxevVqeeuop+PkTTzwhTz75pDz11FNy6NAhiUajcvvtt0sqZXDUJIQQctUy4zehO+64Q+644w74mVJKdu7cKY899pjcddddIiKyZ88eiUQi8vzzz8t9992n/ZtCoSCFwq8tV5PJ5EybRAgh5ArlIz0T6unpkVgsJlu2bJmKeTwe2bx5sxw8eBD+mx07dkg4HJ76aWvTf9VBCCFkbvKRbkKxWExERCKRyLR4JBKZ+uxStm7dKolEYupnYAD/9T4hhJC5x8di22O7xCJCKaXF3sfj8YjHg60zCCGEzG0+0k0oGr2YvTAWi0lLy699jUZGRrS3o3+NcmNR7JeoP+yTWPlRBAkWbYYMg1KHFU/ZBThLY65RH6JQP1be2Yv4mvYSjldDIH2hiGTm6Rt2dQmWCKWd2COvVIdVTJ4GXZEXcGK/KXFg5czYcZyN8c3aDhh323XPqRXre2HZs5MLYbzqNmSdrMNzEa7VTb7icTxWN9Wfg/HjK3A2Tr9fTxtZ78dKx36vnoVVRCQQxuUjHjwX84NxLXa0sRWWdbyLlXc1F/AYxpfosWAfLpv1Yf8wSeJHiclvbHKJXr5syB5s8o7LdGJlG8rOm43izKLecdzPQh2Op9sNPpA1eiNtacOYGDLFmrzjqoandGBIb0vFZVClGcKJTtwW7zhQGBqmHj1/K1ZlVu3s7JRoNCr79++fihWLRTlw4IBs2rTpo7wUIYSQOcCM34TS6bScPfvrvwfp6emRI0eOSH19vSxYsEAefvhh2b59u3R1dUlXV5ds375d/H6/3H333R9pwwkhhFz5zHgTevPNN+VTn/rU1P9//etfFxGRe++9V773ve/JI488IrlcTh544IGpP1bdt2+fBIPBj67VhBBC5gQz3oRuueUWUYb8OCIXRQnbtm2Tbdu2fZh2EUIIuQqYtUntpOAQsU+3mvBMGuxyavVNMd+ITzlVFMcnu/BQoEPBUgDXERrAJ6hVw2GhewBnyKo/qb81xkv4sNl4mGvIAlcs6ofzzhZ84rh6IbY4OjaKxQNvD+Eka163fuJa6zPYKhkONF0pg+VMh8Hq5KAunnD68Zen54PrYbwzgu18Enl90AdGcDI+bw3u0K0LTsP4RBGLVeZ741rMvwCLGF4r6jZJIiK5NizsWbhY//OJ7ii2cmpvxWNy3l0L4/FFuD/IcqfxKF6HuQZ833sMopQyECaoPnyjZOdj0VBDJ/DhERGHHZcfHqrVgza83nLzcD87XsDPj1wTnjcFhqUQMthYGSyBTKoAdB8687g/TmBPZLNKmEAIIYTMBG5ChBBCLIObECGEEMvgJkQIIcQyuAkRQgixjFmrjmt40yEO93SFV2Dk8hNQZZuwOgwlYBIRybYarHUCupIluwSXtSmcZavqNKjjErUwnqvX226yLrEZ3ImKjfgf+M7rY3X4RCcsG2jMwrgrifvj/xG2PkJ2JAmDqi88iZVDgfPY5qbsx6pB3whSTOJ2p84bLJvStTDuyIF6avFEOM9ju5gXB9fBuCuFvxce9Or9QeooERHvCP7AP4zVTefHgaqxAc/DwHFsZVR14/6nFuF6wqf0NW5SkQYH8H2fPYr/9jB8w5gWS7jwggu24dQx+RJ+NNYZ7JkcPv1+Uwlch+kvXBwFPIZewz1RCOtjGOrDismxa7E/J7pPRPC94k7AolIGS7wyg9cbvgkRQgixDG5ChBBCLIObECGEEMvgJkQIIcQyuAkRQgixjFmrjnOnq+J0TVeLuCew8sNe0hVfgWGsDkv4sA9T1Y8VKLaCvk+rKlbxGJV3LVj1UqrByq58s17egYVqUmzE7fYN4H4GBoEaRuGycg4nAKztw/1xpXF87Bp9mRlstSTTglWNvmEcz0XxNT2T+lxkl2NDK3c/VjWayEf0tWUPYQVXug5/z6trSMF49k2cMLAI1GqOEL4f3GexX5spaZq9oI9V8DR+NHgn8MSVvXh+XIZ1607r/Sn58P3jzBvUYfV47r+44D0tdqYBe+GZ6AqMwHiLOw7je9SNWmxoEivSgmfwWJkScVa8eFwml+prK9iH17LpfjMpLBHFWtyOXJt+P1RzBjkvgG9ChBBCLIObECGEEMvgJkQIIcQyuAkRQgixDG5ChBBCLGPWquPKXrso9yV7pB2rMyrAFsozhrMu2ttwl5EKTkTEDuIVF1brpBdgdUvrUqy0GTzThNtS1vtZ7jBkIjV8jVBDuJ/ulN5GNYwrcSexpCZ8CvttmYjmdHOpQh1un72Mr2kv4TGvPYnXRNWtx1Ueq5IK87BszH8OK42afqXXU6g1ZOY1CO9UGn9QP4b76f2FHh9fiVVwRWyFJ6E+XLfYgAdZD15v2Ras+DJm7jSQiehrLjCM759CHVZv2gzdeXV0sRb78vzXYdm+AlYjLvUOwXjUiQ3U/p9F+7TYQFsDLPvfam6F8bpTeE2UPfj+dABxpOn+Cfbjsc0247pRIudiPR5wR0avw5a//PcbvgkRQgixDG5ChBBCLIObECGEEMvgJkQIIcQyZq0woRi2ieOSw+VCnemUF/z7epzEKtuCD1DrOidhfGJMT5zlMCTwqhbwoe1oAtvzKJ/hZBUcoLvcuKzbje0xsktw1dkJXSSAklKJiFQNq8PWhZOJmaxBQge6tVjyc/rhsYiIK4srcZzDB8WRND78jW2u19txCncoG8XXdBv0F7Vn9cRmpSA+PPefHoVx5cVrWTnx90Jb76AWaxlrhWWLTQEYd79xGsbz/3aVFqsYDsOrWNthtASyVQ1Ck+LlCxk8k7jy2lP4Hu+u0RPv7VEbYVmfE9f93NufhPGV63ph/LPN72qxH1xYA8u6ffia3jEcVw58gzqRIMCQ5NIFbJJERLyGRILpNnA9Q8JFf0yvo2IQeiH4JkQIIcQyuAkRQgixDG5ChBBCLIObECGEEMvgJkQIIcQyZq06TpRoqrdco8F2pVFX4HjGse1I/XFcx4gXq6xsNbrcpFI12FcYFELKoBqTMv4OoOz6PzDVcWNrH4y77LiNL59dq8UMebokFzEkGcsabH4MSe3yqxdosbHrDcpAryFJ34heh4hZfZVcrLel6sPts9fgiUv4sYLNXtTVSvkGPFauLqxgS7fjtvgMFkqNR3VFYrYJ376+MayYLK/FisQK6Gay09R3GJa6kzh7nb2E+9m/BfQniu/N5rdwP8uGJHi+C3r5373pOCz77Ak9GZ2ISN0xXPfRAJCNiUiTJ63F+s4aEuk58JrNYxcvaEElgi16AkN4gkxqR88kXiu+UX3+kyvwfVKZ1JWhhrsbwjchQgghlsFNiBBCiGVwEyKEEGIZ3IQIIYRYBjchQgghljFr1XH+4Yo4L0keV3VilUgJJFtKt+OEX+lWgyLNhVU8roRe3tODVTxOg++Z7TT28ioFcX/y1+tKm2oFX7M3rXukiYhcV3cexmVlSgulhvFY2XN4rEY3GrQvhjFs/6FeT+vPcd89CYPKbFL3axMRyUdx2+u7JrSYw47bN9KNlZHuCTzm6QX6PJtUY/YSXhOVOqxKsp/HqjRHXh9z3zi+phhs2VxD2AwvAHzvBr6A2+dw4jHMtOI17h3H/feNgbhBAepK47Y4s/jxlerQK8oasguqU9jXMTMfD6IjhdfEz48v02L2EFaTtTVjn8qRtVhJ6cHFpVCnx0avw356vjE8byW/IVEosMH01eF70JEHvokFWBTCNyFCCCGWwU2IEEKIZXATIoQQYhnchAghhFgGNyFCCCGWMWvVcblGuzjc0/fIqiEL4LwFI1rMXm6EZcO9WGmTug4rvly9ukwEeW1djBsUX3Es+6niZJxSHtG9yZBKT0TkbCEC46aMkQ3BjBYbLmHFjxrCShsHyOgoIuIZw8up6tTHPNdoyNxpmGN7CWetLYZw28d7delQQweWGZmUkd5xXHfFo7ex/iReV/laXId3AC8ik5pM2fVresawP+L4aqz4cubCMJ5rAJl8+w0pVA3Ku/pT+P7J1+J5bv6Zrt5MXdcCy7p7cXbaxizuT6ojpMWeO3gTLOs0JWt2GlSNYUOG0j5Q0SpdiSoiki/j+8SdMLTFMBVOIFYLxPBarn0Lj2F8LTasQ/dhIo3vwSp41Fbw0oTwTYgQQohlcBMihBBiGdyECCGEWAY3IUIIIZYxo01ox44dcv3110swGJTm5ma588475dSpU9PKKKVk27Zt0traKj6fT2655RY5duzYR9poQgghc4MZqeMOHDggDz74oFx//fVSLpflscceky1btsjx48clELjoHfXEE0/Ik08+Kd/73vdkyZIl8u1vf1tuv/12OXXqlASDejZFE4U6mzguUSHVDGDFisuhK1bOb8SSEt+wQd5jx+qmYkhXm5jUKsqPlTP2M1gGZzOlH6zVlW0lO67D4cXtXlgzBuO/H+nVYu5O3JBHX/+3MO7pxqq5ig/PT2q+vswquAqjwrDmAq473oW/R9W16/1vCuiefCIivg6sJDxfwpkxXXH9msPrDYqn1ViRlx/HXmvuSYNcS/S4fxT3PdOKx7DxCO5nuFsf27IfT5BpzfqGsVmYO264WQDFGoOvow+rsspBg2KyEfjsDeD5cV6P56fWh+VdA71YdYt870r9eI4Li/E8mLwn/eN40KsOfZ5N949y4+dHGSg9RUTywE4xEMbecWWlz4PNlE0aMKNN6Kc//em0/3/22WelublZDh8+LJ/85CdFKSU7d+6Uxx57TO666y4REdmzZ49EIhF5/vnn5b777pvJ5QghhMxxPtSZUCJxUdheX3/Rybmnp0disZhs2bJlqozH45HNmzfLwYMHYR2FQkGSyeS0H0IIIVcHH3gTUkrJ17/+dbn55ptl1apVIiISi8VERCQSmf4HlJFIZOqzS9mxY4eEw+Gpn7a2tg/aJEIIIVcYH3gT+upXvyrvvvuu/N3f/Z32mc02/feMSikt9j5bt26VRCIx9TMwMPBBm0QIIeQK4wPZ9vzxH/+xvPjii/Lqq6/K/Pnzp+LRaFRELr4RtbT82oJjZGREezt6H4/HIx4POGBUoh32pdvwRpZJ6TYllQC2r8g3GfbdOD64q39Pv6bp4LdqOhQ0aCEKjfj0zt2jHwqHzxoO5pfqFj8iIi8WV8P4LxoWarEvdLwNy9oMh+QmgUgpYEgElgdJxqKwqPgNwhFHGmeNm/cLXM+5iG7bM1GDhTGrF+IEgOdrsOijXNLXinsStzs1iK8ZOo1vvVA/PoQOno5rsUoAz0/LvxgsZ7z4muc/ra+h8tIsLNtYh61ozq7E9i9eg3gi1DpPi8WXGO4rFxaIoMRrIiKusN72mjYsQLgRCHVERBpcur2ViMiv3FiA0deorzdXFfd9bQSvt5+v1+2GREQyMTxvSCRSDOO5zzfg5JeJLvyc9A/pc+F4uRaWVegR9HEltVNKyVe/+lX54Q9/KD//+c+ls7Nz2uednZ0SjUZl//79U7FisSgHDhyQTZs2zeRShBBCrgJm9Cb04IMPyvPPPy//+I//KMFgcOqcJxwOi8/nE5vNJg8//LBs375durq6pKurS7Zv3y5+v1/uvvvuj6UDhBBCrlxmtAnt2rVLRERuueWWafFnn31W/uiP/khERB555BHJ5XLywAMPyOTkpGzYsEH27ds3o78RIoQQcnUwo01IqX/9L5BsNpts27ZNtm3b9kHbRAgh5CqB3nGEEEIsY9YmtXNmRS514wn3YbXS4EpdJdS5bAiW7e7DShspGvZj8PKXb8YKJuXGb4rFIlb9eFuxAqfQr6v9imFDEriFWMXU3oTVQEOTugIn7MB1OFtwvHwWJ01L3YBtPeyDutrPuRBb6FTH8K9tHZN4rByD4zDedKhTi41swhYysQy+pvcsll8hVZIpGZ1n0mAXkzPZEOE2upNgTYRw3fYSrtuRw+u20KlLmVrq8R+Nd4YmYDzmx+ordxKv25JfvyeaN+C/JUwPGqSUBjxv63Y5/ttwxrh7G16D8aOF+TB+wo3bkh33azFHAs/PgdJiGHdP4Ll3YUGiVIE40mSX40obkiUaEjo6QeJKd8qkutTncia2PXwTIoQQYhnchAghhFgGNyFCCCGWwU2IEEKIZXATIoQQYhmzVh1XaFRi914qscDNVVU9SVSmiH21li8chPELiTCMu7J63JnGe7fDoIKrugyquR6synKCfFp5LD6SjghWh8Vz2FPurq53tFhJ4XG9vq0fxpOfxwnPygavrFNjC7RYJIwlP0NNWHlXqcMJwkwp00J9+iDaDGZjVSf2PWvtx4nNFDLjNfgDplvxOnTlsCop24J7ZC/q5XMNeLxNyjv/eYOhV0pfh51LsAru5tozMH6wuBTGcxGDz2BY788nGrF58T9ei+dHnLju6Mv6GCJVqIhIrR17Eg6X8PNgnjcO4756XRna0YXH8LzhWZNz4HvWnTSo0oBXpRuLACXUh+c+14TvZaSmMyU0LIb0slXgF2mCb0KEEEIsg5sQIYQQy+AmRAghxDK4CRFCCLEMbkKEEEIsY9aq40rBqth90xU0jjxWDjlcumzD59IVcyIijV7sWXZ6CHvKVdv1fbrajj3SKqOGVI8G/O3YnysDsnG6m7CP24aGXhg/ncb9SZZ1Bc7xZAsoKWK3YQWXSQW3pfk4jDvX6vV01YzAsv8QwN5cg5uxoqj+hO7ZJSLi79NlQvaowQuuipU8uSasbIsv0vtvSMQpnjiue9LgEVdYitdWT63e9qoXz497HM+PK2dIpwKa+Ob5Nlj0QgbPQ6AX9yc7D7dRQvr9+eKxa2FR9ziuu+LDY5vs0Pu/bj5W3pm+hW8MYBXgP5XW4H/wtq6+O9WAlZ7VOsOz6TSuunkfVqkWuvRs1fl6nCHamcIqwPqTeAsInNJVt8qH74fRDXrfqwb1J4JvQoQQQiyDmxAhhBDL4CZECCHEMrgJEUIIsQxuQoQQQixj1qrjlK8q6hJ1XCmI98xbOs9psUQJeyK9dnYRjNuGsXKqGAa+SCXD3m3wD7M1YN8mmyH9YHCerppLjmHvtP/vJFbr/N6SozB+KqUrauxIHiUiXgfOZPv2Od0LTkTka20/g3FXk65edBmMqEzZaZ1ZQ7ZQ4KkmIlJs1pVJ+Xo8QYGYQQXow+ULjXr5UhCXLQUM1xzE/Sk04nWomvU1pDJYCdX8Fh5bZxrHvSP6Nb0dWE3VEcR+aH3zscLSUcD9X7pAz3z8iYazsKxnHVaTvZPCCj63XV+3NwR7YNlOF1awOWxYRTtWxOVRZl2bMjwnDCpa3zi+38SJ1YGeExe0WOr2hbBsps3gvZjHa7/QVqvFKl7cHwU8/FDMBN+ECCGEWAY3IUIIIZbBTYgQQohlcBMihBBiGbNWmGAr2MVmn75HulL4kLM71aDFemN6TESkmsaHuXXncN1lvx4vBfGwuRO4Dk8vTlaVacXiCdWiJ1OrP4TbnY1iK43/Gb8exm1ecDidwf1xxfF3lLZD+ID7K/l7Yfz+m1/WYos9w7BsbVscxm3vGrL6GYh36Ye/MBmdiORrcT/jy3DdNnBO3viuwZ5nCb6mwRFJGt/G8bE1en8chrPfySWm75Z4nv0xvaLJ7jpY9tUktkmqO4b7mYvgeN+kXv/xvk/AsqE38X2SixoS5tXo8VdbF8OyHWufh/F/it8C42+8eA2Mt57Q7ZZG1uD7PtWJJ9/+jiF5XSNOyOeY0MUTVcMTPXQkBuPKjZ8rxVb9mulWXLkD5Ke0GSzWEHwTIoQQYhnchAghhFgGNyFCCCGWwU2IEEKIZXATIoQQYhmzVh3nHneIwztdYeHE+b6ku1dP4ObwGywwDJiSkgViuhLMmcF7dzFsUAg1G2RMdhyvAmVJMWRQWZm6abikApZDgRZsUVIZxgnMHHmDhU4Y26vs7V6nxb6y5FVY9sGuAzD+3Vt+B8YnV2HllEvPaScOXXQoIiIFg2pOFO5nYFAvX8ACJmm6SbenERG50FUL464e3J+KHygSkdJRRCoJbAvTeDNuy/lhXak2PzIJyyZyhvHO4mtmHXhs03GgHDMoqvwjBmuZepN9ll5+eQSrw65x48SSv3TiJJLZhdjOqKcB9F8ZVHCN2MZraBMe247/hfuZWdakxRJLYVEJjOAkl9lGvAVUQFMKdSYLKvDvDXZNCL4JEUIIsQxuQoQQQiyDmxAhhBDL4CZECCHEMrgJEUIIsYxZq46r+JQo73R1Ur4Nq6+koisx1rf3w6LHRqIwPn4tljfVHdf36YrXkMAMeFaJiJRDWCVjK+F6kLIvvcKQ7G0Ee8d5Y3hq81G9bp8bj6u9F1/T/84AjC/47/NgPLFQV1/tmLgDlnX5cFscJw1JuQwqQOTN5sDCJrEblpW9iOfHmdEvWncWS+8mfoDXW3UNVraJwtcMntXnMzCEv0PWvTMO4+e8uC22gN6fYU8Qli2NYT+0hhgexEIYq+ZW3tqnxU6M6AkXL9aB701lmHzfkK6yO9mK6w4vwvfPF8JvwrjjBnwv/49uPblkKoHH6uaFehJOEZFfJLFZ4eQyvPbtZb3/pQaDXNZwn9RcwDdFpkUfl5wuxhMREQcW+102fBMihBBiGdyECCGEWAY3IUIIIZbBTYgQQohlcBMihBBiGbNWHedK2MSRn64UqvgN2fqA8qMviTNDmqhbNgHj8aqeodWNbbVELcZ+UyqJFTjuMZzVsCS6cVNtZxyWzfVj9VHFg+Uw9oL+vSNl8P3y1WClVmJTO4ynFhi8v7boWVSXe7ER4No6rLz7sX8FjMcnsXKouUn3BKs1XHM4hZVgqd5aGC806ONS9mMlVHoBnodb1pyA8Vfew+Zf9pK+hpLt+DtkYhHOKlzpwP13DOjrzevBardSGWdWNWUbRh5kIiJuu64O7GzA92B3E/YwVEux52EWeOfZc/hem6hgadfexAYYd9mwqnHLgpNa7F9GOmFZD+i7iIh3CI9h+Cx+rjjTurJt+BP4fogvwv13FPD6rD+lqz09KVzHyFr9vq8Y/CURfBMihBBiGdyECCGEWAY3IUIIIZbBTYgQQohlzEiYsGvXLtm1a5f09vaKiMjKlSvlv/7X/yp33HHRgkUpJY8//rjs3r1bJicnZcOGDfL000/LypUrZ9ww5bj485vYgD3PxbgeGz6NPSaC7SDbmZgP5x05/ZoufB4qlTP40NZWi60+jEnWWvUOtddiNcTRcC2uxJA463eW6gfiW2rfg2V31t4G4+ePYvsX7whuisuu9z/iS8GyQcOgzA/jeWsK4GyE3cONWuyGJbpVjIjIRA7Pmy+Gv6Plm/T+lIJ4bVZq8CF0b6oexqWMr1kFZ8LFFpP1jyGcxbe7b1xve3IMH3BHusZgfCKGk6blI3jtb2k4psVeHFmN64jiftoreKxc43o/Kz4smvmfKfxseqHnWhhPG6x4Fs0f1WKmBID9Liyayrdiy53Jpfiavgn9meUM4vs+cZ1BqJTAa6JmSF9wziyeS/8gECYYLLJgGy6/qMj8+fPlO9/5jrz55pvy5ptvyqc//Wn5vd/7PTl27OKCeuKJJ+TJJ5+Up556Sg4dOiTRaFRuv/12SaXwA4cQQsjVzYw2oc997nPyb/7Nv5ElS5bIkiVL5E//9E+lpqZGXn/9dVFKyc6dO+Wxxx6Tu+66S1atWiV79uyRbDYrzz///MfVfkIIIVcwH/hMqFKpyN69eyWTycjGjRulp6dHYrGYbNmyZaqMx+ORzZs3y8GDB431FAoFSSaT034IIYRcHcx4Ezp69KjU1NSIx+OR+++/X1544QVZsWKFxGIxERGJRKZbpkcikanPEDt27JBwODz109bWNtMmEUIIuUKZ8Sa0dOlSOXLkiLz++uvyla98Re699145fvz41Oc22/RDTqWUFvtNtm7dKolEYupnYAD/xTwhhJC5x4xte9xutyxevFhERNavXy+HDh2SP//zP5dvfOMbIiISi8WkpaVlqvzIyIj2dvSbeDwe8Xh0lUc5qKR6SVI7UxK4arOuCAm9iZUpCW8NjEfasPpseL7eNk8c2/A4M7h9TUdgWFxJrGRJxfT63/XghHHuBP4eUXBji41/GezQYhNFrA7r68aKJ98kvmaoF6tnhg/parqBBqxe/NX5a2A8b1CCOdK4LTYgBvqxWgXLVifxfLacxdfMgf4rw9e57Hwc7zWMbfRVXJEzr7cl14DLJrFbjNgMajKU1M/Xh8dkxIktdKLdeO6rbnzNLrf+25HfbcKPo/eaWmB8bdt5GB+or9Vi8QxWmAUd2MpocT1WAb49hi2remK6GrOSwf2phrBQa3HXEIxfGMC/HaoZ1Me8Mo5Vvraq4dlpUG+OrdKfH/5hrLBTDr1uFDPxof9OSCklhUJBOjs7JRqNyv79+6c+KxaLcuDAAdm0adOHvQwhhJA5yIzehB599FG54447pK2tTVKplOzdu1deeeUV+elPfyo2m00efvhh2b59u3R1dUlXV5ds375d/H6/3H333R9X+wkhhFzBzGgTGh4eli9/+csyNDQk4XBYrr32WvnpT38qt99+u4iIPPLII5LL5eSBBx6Y+mPVffv2STCIXYoJIYRc3cxoE/qbv/mb3/q5zWaTbdu2ybZt2z5MmwghhFwl0DuOEEKIZczapHaBAZs43NMVFoZ8WlKJg6Rck1itk3DjeMCNzY5sDl0Rkuo0JKUaxv5UngmcIMxewm3xxvV480tYrRTswwmvhjfgwSo061OeLmFFzW1rdH8vEZHDrVjylSrgZGreVbry8PpmrAQ6WMVJ3UxUAngMV1zTr8XKVfydq2YBVim+U4/7Wc7oyiG7D/t+3bPqTRh/dXgxjJ8vY9WcAuvWM4T7U27Fa1mBhIYiImLX10Ro9TgsuqWlG8Z//u4NMJ5vwePyVk6X8LW58TU7m3Cyu8834bH91vDntFg0jBVpm324P31hXe0mIjIyHx8tXBjUvQC9g1ihes6LlaGqZFCdYntE8Y7pPov1R7D6N9OG1WpFg/0gyrvnymJ1nKOoxytFfF/Ca112SUIIIeQjhpsQIYQQy+AmRAghxDK4CRFCCLEMbkKEEEIsY9aq4xx5JY7qdNVFzmBB58zqyo+yz+BdlMcKtu5zuHJPna5AKeRwHUhRIiLiTBvUSk5DZsiUriiqOvFUTazEnlipZViRt7ReV6olC9hnL1fG6p4F4TiMv9OJfcWQnmhZDXZWjxv60z2GlXe5MawCHErpVw15sQqufwJnuiwbMpF6hkDmTjcu+5Pwchj3urBqzJEx+LtN6HFXGq9x97tY7ZhZi33SisBXLFKD1WSNhrTCqSW4P65anCl3qKivlbzCY2hahxXB/c8k9PU8DEuK9JVDMD5YwGvZpLB0xfQ2ln1YTeYL4HWYncRrv7AJz8XkuK6EC17A82B61Hu9l/8ekp6Hy9af1J815ZLhYQjgmxAhhBDL4CZECCHEMrgJEUIIsQxuQoQQQiyDmxAhhBDLmLXqOFdWibM0XV0S7MFqmHCvrsAp+7GCLb4Ed9mJhUNSCer12AJYgZLpxGqYdEcAxv1DWCXjzOr1Ty7Fiqf0AoOfkx+3cUloRIt1eLFn15EU9k5bWYN933JLsYop6Nbn55M1J2FZU/xZ7ydg/EwN9uFyOXR1zjc6fwrL/peTvwfjBQ/uT7FBXxPuMbze6v14YfWPYUWeHS8JqQCllTKo4xRutjicWLHkatDXSosvCcve4D8H43sSn4LxQAtWhv79e+u0WBV48l1sIPYhOxbF69Me1+tRp/H98/IirF6sdeF5C3rwBGUm9LnIrMJl8znsAykG77iqISsqyuabieDnm8n3rWoYcqz0xe1wZkHhMtVxhBBCrgC4CRFCCLEMbkKEEEIsg5sQIYQQy5i1woRi0CaVS5LauVP4cM2Z1m0jKm68v9pwFeLIGw7/unUrDbvBEUgMeZwKOA+WFILYpqMKzi3j6/Ehp8ODDwDdbixMmCjqIolj8RZYNlvCp5av9+oJyURESpP48NdRqx9Ox6PYbueNzCIYf814TWw5dNPq01osVsZWLDcZErUd8+FxyTXp45Joxe2YH4jD+HV152E82YnreX2wQ4spnBdPclk8D6EAttBpD+tWTq3eOCz7D5O6oEBERIHkjyIi6ZNYgFEN6evWHsRWU7Zh3J/nj10P46Ez+r1fxrne5B96roXxtto4jNsF97NQr8cXtGLBz7oGPeGiiMiFfC2Mv3G2A8YrYFj8o/ghlG3Cz8Mkvt2kVr99RGHtjcAhMTxnEXwTIoQQYhnchAghhFgGNyFCCCGWwU2IEEKIZXATIoQQYhmzVx0XsonDM12GVg5gWZq9oiu+XGmDamwS11EMG+QcYJs21VHBwibxTWKlms3gbJGJ6jIUhxurXqL12F4F2daIiLz2zhI96JyBlEXEqAK0mexFQLy72AzLtrjjMF5KYIWUb9CQ7G+Zrr77X6NYCXVbwwkY789gZdfZPj0BojeI1YuL/KMwfjyFlXevn8MqQNuYLpms+vBEuEAiRhGRiSGsDuyqH9NiLa44LDvPrSvpRER+1gbWlYg4j2BZGkroWDXc38qL1+f8hgSMD6zW1Yv2rEHalcI3bSaArXW+0v4KjD9V/rQW29SEVZfrAr0w/nfZG2C8JRKH8cHrGrVY9Ti+H0z2PD68PMVW0cc81YHXmzOj35uVohL5Ba77UvgmRAghxDK4CRFCCLEMbkKEEEIsg5sQIYQQy+AmRAghxDJmrTous7Akdt90RYszYUjYlNJVNfYy3l/zzSZpFw47Qd0mqh6Dr1QIK3OqhtEv1ejX9B7FPnOJDViVVang/rvH9bYUW7Bnl3McS2qcWTwm3jUTMJ7o11VZPx9bBst+ouEMjNu8WO1X8eBBPJ/Qr3ld5AIsu29sBYwfj0VhHFEs4HZUUOYxESkb4sEQTqY2ry2mxU4fXgDL3nhdL4z/6p9XwviR2nlarDdRD8suDGM/tGIcqxdLrXjelB/EK3hduZJ4rAYGcRtRPXXHcN2+CayC678Zqxe/cf73YRwl0ss2DsCybS48hvkKvt9aAlgBO1RTq8WqLrwOveP42WQvX74y1j+I58E3oc9luWR4zqI2XHZJQggh5COGmxAhhBDL4CZECCHEMrgJEUIIsQxuQoQQQixj1qrjRNku/lwG6Ta9XKEeK9LsRUN21oVpGM8Dz7KiQXlXdwRf0yB6EXfaoFgBYrWRW7CCTUZ13zwREU/MMLVgSH3dWCHkH8btKxmyVMYncFvEoytlzow0waLz/XEYVyU85u0/ysL4BeD7dmwTVmrlCrj/tTVYqVbfpKubChU83uMlPCYjWZxut8aL1Y4n+3WlnjuDx+QX7y6F8WYsPJRxn97GMTG029cA4y2v4ns1X4/jmfl624vN2GPR9BhwxfC8eSbQP8BruViDxzBsGKvkQnxNV1q/5ouv4Sy0/xhcDeO+swaFocHXEj1tylhEKyWcyFgKdYb+d+v3bGBoBsriyxcV802IEEKIdXATIoQQYhnchAghhFgGNyFCCCGWMWuFCa6EQ+yF6UdvFYMtjjuun4J5JnHZvMnp4xw+bbeDa1bD+AC1/LspGM+ew8nE3JP4O4CjCGI+fE2nEx+2+6OgEhGZHArpZXuxcqLiMSQZM+QHm9eCE57V+3TxwI11PbCsw4YPPzcuPwfjRz69HMbVdfpcXNs0BMv2pvCiyJcNCcLASfngJJ7jFj+2XLkwVgvj5Sy+pnvYoG4B2DMGUU7JIMoBAoeKIZGcycbKdPBtx8tW7CW9niUL8fwElmKxxtunOmC8/phhgQLKhjUe6scNzzfiechHwH1Yg+toasJrYrSC11BHO84853Ho9cfzWJkwHKuFcSniZ1DNBX0My4aknd5Jve+Ktj2EEEKuBLgJEUIIsQxuQoQQQiyDmxAhhBDL4CZECCHEMj6UOm7Hjh3y6KOPykMPPSQ7d+4UERGllDz++OOye/dumZyclA0bNsjTTz8tK1fihFomoGtPE1bJ5AXYXRiShnlx3jXxjmI1kLID9YwdK2TspVpctyFvlMn+BiW7qwthe5rrI/0w3p3C9ioJvy5jKgXxMmh8Dyvvkgtw+daaBIwfHWrVYhM5LKe6YEhU5g9jC51iPVbhVLP6HCWKWN5ze+QkjJ/MRGAcUarDiqwT480wPq8xDuN95xth3JHT12G+CffdlHwsEMvD+Og63YoGqddEREr1WPE1thGGxddvUJOBRIqtAbx+XnkHJ0C0GaycikG97Ta8lGVypSERZT1ud9lvsNrK6W2pKnyfjBqeE+4RQ4JGv25BJSLi8+vPw4YAfk64A1gtWxRsQzS2Ru8PSh4qIhIY0eNV2+X79nzgN6FDhw7J7t275dprr50Wf+KJJ+TJJ5+Up556Sg4dOiTRaFRuv/12SaWwfJkQQsjVywfahNLptNxzzz3yzDPPSF3dr3dppZTs3LlTHnvsMbnrrrtk1apVsmfPHslms/L8889/ZI0mhBAyN/hAm9CDDz4on/nMZ+S2226bFu/p6ZFYLCZbtmyZink8Htm8ebMcPHgQ1lUoFCSZTE77IYQQcnUw4zOhvXv3yltvvSWHDh3SPovFYiIiEolM/116JBKRvr4+WN+OHTvk8ccfn2kzCCGEzAFm9CY0MDAgDz30kHz/+98Xr9fg4SAitksOpZRSWux9tm7dKolEYupnYGBgJk0ihBByBTOjN6HDhw/LyMiIrFv362RNlUpFXn31VXnqqafk1KlTInLxjailpWWqzMjIiPZ29D4ej0c8Hl3d5h+0ieMSXyf3cbzxZVr1Da7xPazi8Q1mYDzdiaVqNef0ZHepxbjs8I14o7WVcbz2pClpnF5+vAcrZILzTsP4ktAIjPdP6PXkAziZlsk7Lo8FXHJqDCvBCsO6Ei5+GCd186zFAhanAyvBcgY/QVe/3qf3LiyGZYub8G3QH6+F8Uyv7vEVPonHym5QZeWzuN0Lh3DyQldCV47Fl+Ex9E4aEiAaVJrBXv27qMlnLunAYxU+hesO9WFF60BQV2W9PtCB6z5mUNg14jYiJVyx1uCDGMKqsfQig/+cG69D55jeRnsef8evGubBkcdtXDovBuMdAT254mAO+89F5uP7ym5YFKcm9KSTk+N4vSVH9XutUrj8rWVGb0K33nqrHD16VI4cOTL1s379ernnnnvkyJEjsnDhQolGo7J///6pf1MsFuXAgQOyadOmmVyKEELIVcCM3oSCwaCsWrVqWiwQCEhDQ8NU/OGHH5bt27dLV1eXdHV1yfbt28Xv98vdd9/90bWaEELInOAjT+XwyCOPSC6XkwceeGDqj1X37dsnwSB+lSOEEHL18qE3oVdeeWXa/9tsNtm2bZts27btw1ZNCCFkjkPvOEIIIZYxazOr2qq6ysVgByfZNl0Jlxs0ZVcMwChIlikiIsUGXZGXbcZ1154wZKPM47ijgOO5iF6/8mOZVYs7DuNjJfzrz/oa3Vuq/roxWPY9ezuMNy/CyruOMDbmOwFiqhur/e7qegfGD03gtvzuTah2kYGsXn9fCl8TZUoVEalUDOqmoL7ekouwgssHfLVERCpuHM81YaWivazHbRW8fkLdWPGl3Lg/rpReT6ILFpVqK/afGw/jR8nkNXhcAh1xLVYu4/vKlMm3HMD9r3j1fubrcVmPwVOt5DQ8Gg3PiUoANNKgjDT58jmwPaJRwXZzSFfGHnPNh2U7PTg760/HV8F40KOPy4RB5VsGj9TKDHYWvgkRQgixDG5ChBBCLIObECGEEMvgJkQIIcQyuAkRQgixjFmrjnMnlTjc01UhnhSWmyBvtvE1WFESPoWlNuEe7DWX7NA9rtxJUxZWGJZcA/7ADVRJIiL5a3SZjCmL5D8NXQvjJsVXvU9Xx/VOYtWYifE49s6Lp30wXsjoY2jrxHN5UxB74aUrWDX2zuQ8GD9zAfjYGZRNfpDlU0Qk4MXKqVxO738lhNePswerw0yKL4dBSekBay7ZjtfE5HKctdbkHZdcqMdsS3TPRBGRTy7ohfEjw3geskfx2koN6epNRwjPQ96wVlQAx4txfb154njyi914LZu+nZu8AL1ABelKG7KwGuoo+3D5My8tgvHv/45+zXge34P/79CN+KJpvAU4G3QVJPLHExHxTOjtrhQNiw3ANyFCCCGWwU2IEEKIZXATIoQQYhnchAghhFjGrBUmuLJVcZamJ5AqhPBprhOcofqG8UFkqA8ffnqG9QN7EZHh9XqSqHwTTmw1f9kwjNc58TVPn26F8eWtej1nY3qSKRGReA4n+ovU4INllAgr4sUJr15X2Crn9xcegXETf3v8ei3WOk9vh4jIe7k2GI+X8IHryvAQjHf/aoEWu2EztvhJlvAYpu36AbeIiKtJF46sbMHtGGzDScZM4o6GH+G2+If1NZSeh8UagSEskvCO4DXuzOsigUwc2z79y0ls81IMG8Q6zbgtnpj+6CkV8Hdi5cX3W31zEsbzZ/Wsi95R3L5sC4575+H7x2FIrphs1L1rao/ig/wiXlZSxktcXLgpcnZU76epfcowtk2HcDyxWBe31FzA7XAg/Q7W9ED4JkQIIcQyuAkRQgixDG5ChBBCLIObECGEEMvgJkQIIcQyZq06LtHpEIdnuhrOO46VLChxmCGnm6RbDcm3urCKqerWr+nMYeXd4FgtjH9p5ZswHlhZgPFEUZfJfGoRtrNp9+JEcu0enKiuwaFLbX4wvh6W7WrAibDOZXVVjojIe6MtMF4e0fvTl8fz8Pf5tTCePVIP48UOPIZdL+j9fK12CSzryODvYpUarDRyhnTpzztvYmsVWxQngatkcf8LYdwWe1lXWmXasf8LKisi0lDB8qtSjb6eUyuwvMmkSFsRnoTxt092wLgjr1+z0Iz7E4pi9eaiOqywPCb6+iyG8T3rwlVLqYjnJ1SLpWpph64mK9Tiut0JQxyLaKXpbaxqLJ3W57NUg9dPjRP3322wQku16/2v4mUlwdP6PVguX748jm9ChBBCLIObECGEEMvgJkQIIcQyuAkRQgixDG5ChBBCLGPWquNcGSWO0nRlWsXguZRu11VMgfN4fy37sEqkaqi77qSujhu7DtdRyWNvu3gJJxlzO7AyJQPMpU7FI7BsU7PBI86FlW3/Y/IGLZYweKdVDVn60iXsWaYMifSkDihlcnisOmqx2q/1jl4YN3nKdXcu02L+ftyf7BKssAuEsbJtVUT3iTsXworBsVgIxj0X8IKrieE14YvpbXFk8boq4+kUZcfz48zpa9yexI+GuFv3SBMRmRjB/XSPGpKm6fZ7Yqvg9tX5QWERua0BewG+tUr3DbQb7rXyMB5DU1tQUkgRkZFsg35Ng9otcR1WjtmcWI1pq+A2Fmv1mH/IkMyzF6/xUgDPTymkt6XxPYM/IFDeKVMGSQDfhAghhFgGNyFCCCGWwU2IEEKIZXATIoQQYhnchAghhFjGrFXHVZ02sbmmKyxcaazOcAAvN4OwS0o4oaUoLNaSElDTVSJYaVJXl4Hx3gz2PStXcSNTOV19llRY8lTfiq8Zr2JFzf7epVqsoQYrfkxZW9N92GfPmTEoYubr41VzFhtRva06cdyFlUM+g4ItDObTjW3PpK4F+555nDgrKJq35Q0xWPa1OFaTIfWRiEgmYvCxc+kqQGXH94PY8DyU/bjuYJ8+P6kFWHWYqzfMcRnHTfdhcEBXq1Wd+CZ0LcPKtqpBjbl50RkttsCHVZcn2qIwbro3W33Y+O1cQs9CXDGoFB0+vK6q41h1eqlK+H3sYMztuGop1eBHfdHkNdenx0s+vGazjfq9XCniOUPwTYgQQohlcBMihBBiGdyECCGEWAY3IUIIIZYxa4UJpYBI9ZJzOic+gxdnVj+gyzcYLCYMAgRXB7a/ySqQHS+BD9UzXnyw6AzjA72QBx+qj3v0w+yQF5e123DdeYMPUTSsZ/HqH8HCiXmNcRjPIr8QMR+K+k7oJ7SFOoPIJIi9TlxuXPmKCBYE9Aa6tFg2iq8ZP4/7L2X8Hc0GDoR9LXj9VA1WTs4CPlQP9RsOrV16+abDuH0lP+5nugW3ZWStPj/lAF5XJjeWee04wdxICGeXzPXowplgP77m2W4sHphowiqjSZAUstaFVQImAUJfAq+JWAbbE6Gv8ybbnplSceNBd4BHgrNgWOML8aM+eB4LCDwJvZ5iyGB5BtZmxSCOQfBNiBBCiGVwEyKEEGIZ3IQIIYRYBjchQgghlsFNiBBCiGXMWnWcrXrx5zfJN2LFBbJjsZcMNiIGdZyjC6uScmFdJeLIG6xVyrjyOg+2xRkvYEuX8d46LZaJYmlg2wJsRzJY0usQEcmWdGXf8nlYYdbkMSgGV2B1YKGEl1Ph3VotFuyFRWUyhFV9znnYKsmEDUxncR6WK33mmqMw/qMj18L4goUjWsykdOy26cnORETKIdyfWBErvjzj+npuPozXVb4JqzTHV+L1WXtaj5mUjiPX4/nJhHG8PI5VaaWg3h8nHkKpP4TX1V97bsL/AKhX36mbD4uqOG53oB+P1UQUK/g8wDrMN2JQ6B7Hllqm8r4JrGCLL9bbGF9ksGYawO32D+FBr7r1uktBPA/jK/V4xfCcRfBNiBBCiGVwEyKEEGIZ3IQIIYRYBjchQgghlsFNiBBCiGXMSB23bds2efzxx6fFIpGIxGIX1VVKKXn88cdl9+7dMjk5KRs2bJCnn35aVq5cOeOGOYoijksEJ0WDbRNKnBUYwkqT5EJcx+1teiIsEZGXSsu1WLQWZ0e7pm4QxlcHBmD8v/dtgvFFy/V6VtYOwbLL3MO4DtcojP+3kVu12LgbK7KOlVtg3OHESptoPR4Xz03ntdjZngiu22/wTqtitePh4zgJntygK4oi0TgsmqtgtZ/NjVVJA8O68rBaxHIgRxzfYp4xg4rJ4J/mG9fHxZnCCjvvpTfO/6b2LFbNZZtAWwzeX168rMS2CN9v/lassEzZdWVozXk8Jv5hvCZSHbg/SBlrH8FJ+nzDuN2mZ03A0EaFptmQczDfhOc4cAGPuck7DnlpFgw2iJlW3G5nHqsXPZP6mJsS4HlH9Y5WiobOA2b8JrRy5UoZGhqa+jl69Nfy1ieeeEKefPJJeeqpp+TQoUMSjUbl9ttvl1RKN80khBBCZvx3Qk6nU6JR3dVWKSU7d+6Uxx57TO666y4REdmzZ49EIhF5/vnn5b777oP1FQoFKRR+/Y0umTTkYCaEEDLnmPGb0JkzZ6S1tVU6OzvlS1/6knR3d4uISE9Pj8RiMdmyZctUWY/HI5s3b5aDBw8a69uxY4eEw+Gpn7a2tg/QDUIIIVciM9qENmzYIM8995y89NJL8swzz0gsFpNNmzbJ+Pj41LlQJDL9d/2/eWaE2Lp1qyQSiamfgQF8fkIIIWTuMaNfx91xxx1T/33NNdfIxo0bZdGiRbJnzx658cYbRUTEdsmBplJKi/0mHo9HPB58wEgIIWRu86G84wKBgFxzzTVy5swZufPOO0VEJBaLSUvLr1VVIyMj2tvR5ZBpq4rdO11FopxYceEZ1ZVJpiyAjhy+3ok4zt5YOacrx/rd2PPNvRqrqX50chWM+/xFGI/1NWuxs16sVBu5FmeuvKG2B8ZdXl31ogxCFpcHq5Lqgtiz7NFFP8b1ACO3vTU3wrL9aex553Lgsa1tuQDjozl93hx2rEp6tXsxjDc2YkFN7uUmLZZZhZVqVcMdll+JF2KxDquVlENf4y2vYQlXMWDIuIpFkJK4VvfUCx3HikGT4isex/eEyhgGwK3PRaYFl3Wn8b1cimIvQF+P7gfnN6hlC/W47sAFvFZyzaZstnosfA7XET6DlZTFMAxLpubyPTNLIXxN7yhut0nx5szocU8S34O+cX1sy+XLTyv7of5OqFAoyIkTJ6SlpUU6OzslGo3K/v37pz4vFoty4MAB2bQJS5EJIYRc3czoTeg//+f/LJ/73OdkwYIFMjIyIt/+9rclmUzKvffeKzabTR5++GHZvn27dHV1SVdXl2zfvl38fr/cfffdH1f7CSGEXMHMaBM6f/68/MEf/IGMjY1JU1OT3HjjjfL6669Le3u7iIg88sgjksvl5IEHHpj6Y9V9+/ZJMIh/ZUQIIeTqZkab0N69e3/r5zabTbZt2ybbtm37MG0ihBBylUDvOEIIIZYxazOrVj1VkUvUceLCyo98p66+yhcMXl4pHD/dg9VxSCNkUpqcOa+r2kREHMMGz64IVr3YgJDHZvBO6/CPw/gvJ7DiywYq72zC2VkryJRPRK6r073gRERq7Vg1d7KoK/tSZTwmX1nwCowXDSlxN3mxOu6fs7pJYE9BV7WJiEzkcKbLhWE8tm/WN2oxVcbz459vUNhdwFK1S7MJvw/yQ/OOYkVexYXHtqRwG339+ip3x7GarNxi6OcxrOpzGLKlFoEI0jNpULCF8NwH38Prs/lt/aKODFZrFRpwu32D2PPO24rnbQJkG8414PaFerHq1GaQqU4sxUpF/7C+WPKGa1ZxAlnJGlTEyg6ypRr+kiYPFIaVQlXkZ7j8pfBNiBBCiGVwEyKEEGIZ3IQIIYRYBjchQgghljFrhQkN8xPi8E8/YJxM4gPk9e39WuzUGBYJVE7jrE/pCD4RDq7UD6cnhrC/hmMUn/7ZDQ4W5awh4VlS/25gM9Txd29sgPH61gSMF/P6IedwCv8dV8VwkN3jboDxv8jdBuMnxnTbpqqh7sdivwfj2TE897dddxzGh/N6n46eWADLmgQviTfwGgoN6AfI4RtGYNk6DxZr+FuxUe+JcSyQSb2lj7mtbEiAN4oXS6YFnyzn5qPy+DC86sKH595Rg02WIbmZ/5QeNx2qJ7BjlfgMvsi5Rr3tqbVYgFB3CosElB23xVHAY+5K6f0pGex2MhEstHBn8FjlG3EctbHjE32w7MBkLYyvM6zDgz0g++cFnBjQVtHbZ1onCL4JEUIIsQxuQoQQQiyDmxAhhBDL4CZECCHEMrgJEUIIsYxZq44bHwyJ3Tdd0eIdxIqdXxU6tZgpmWtrP07MVHVj9czEEn2fbvkZVre4slg5M74SD3PT27iRuQZdWRL/BPY/sVVwHe3hSRj/UudhLfbaOLb4+VzzOzDe5cGyJK9Bwvd9j55PajCHFYZ25FkkIuUm/H3p9rr3YDzq1NWBXxm7B5b1e3C7J5JYSWkv6G1ZFxqFZS9ka2E8X8Fr+ZMtZ2H8h1F9vAqNWO02sRyvt/QSnESxdb5u2zQoWAGJktGJiNhLuC0VfFuJb1gfw6LBbL9isJwpGJqYbdHrNiXEdKXxvewdw/FcsyHZH7gNfWP4mjUX8DwUw3je6k4YVHateuzMBazodINkliIiVYM114p5+j0e6sDPoEMvL9eD+DEL4ZsQIYQQy+AmRAghxDK4CRFCCLEMbkKEEEIsg5sQIYQQy5i16jhHoCx2/3RFR9WFm7tkwbAW6xnB0pmR9VhqU5mXg3GUTK7iMahVorh9LpwfS5LtWIGDkkdtXNiD67ZjGUp/GmQNE5FCVVf3VJG0R0T2Dl4P4xEfTtRWrOL+nAQ+fqUSHqtwAM/DTZFuGC8pXM+bIKldLm1I9nYmBOMuLGKS2rP6mL/y0nW4sEGl6UrjD84EOmB8yY8yWqziw30vBvE8SBF/5xwe15V39iyuQxnqqLixEsyRx/0Ey1CK9Vh5544brukxXLOgXzN4Gpd15nDcnsaTX/suVoiVa3VfNeXC7bbnDEo1Jx4rdxyXzzXp61kl8fNtzcJeGDfds6tCg1psqIAVrWUf8I4zqFwRfBMihBBiGdyECCGEWAY3IUIIIZbBTYgQQohlcBMihBBiGbNWHaeqF39+k/CaMVi2wasrhwbfwlk0yzhBp6hBg8kVINeIVSyBIazuGVuDy1e8uHzorK5Ysdtw2XneOIw3e7CCzW/XVT+3NJyGZcdKNTCeLOMMiwFnAcb7k7pSL2PIrFosY7VOSeF4wI6vGXHp3nFOD1YZOfJ47ks1eMzz9fp3t1IbVlM5hg3GZwbxkCuDxyW2UZ8Lw/RIscnQzxQew8YO3TtuZMKQJTiPv7cWW7H/nnMMe635QCLa0Bnc9+AFU/ZTGJZ8nd5PdxrPpbIb5ItOQ+UGZVsuoq+h4C+wD2Bl8TwYT7fisXJlDb53IBOr8mK17OtndX9NERFfDb5/1i3Rs1W/cHY1LIsUkDaDKhLBNyFCCCGWwU2IEEKIZXATIoQQYhnchAghhFgGNyFCCCGWMWvVcTLhEclO90Yaq+A9Mw98yDLzsRrGmcWqDZOXF/J9Q95uIiIGGzepP4rjuSasVkIKvloX9lQ7m2mC8TYfzqx6NK0rc0bzWGbVEdBVUyIinwyfhPFfJpfAeK6oq35aQ0lYNuLH8QaXroAUEamYJFKALYtOwfiP86tgXAHfQBGRiQ16rKkJtzsea4Tx4ABenyU/vqYNrS1D+5TN4ClXh695TcOQFvtlBisg8ym8+I0quOHL946zlbEKLNmG+1MTwzecf1hXsNmquO6KD6+fUh1WTBryqoq9BJRq83CW02IYKw9DfVhhaVriroz+/Jgo4cKuIdzyhuvxc+Kd5HwtVjWtNzA9BktHCN+ECCGEWAY3IUIIIZbBTYgQQohlcBMihBBiGbNXmKBEtzZJ4+ZmnPohorMZH+SXR/GBYxnnNZMcsMHwn8UHi9lmvKfHV2Grj9oWfJidTujKhIW+UVj20+ETMG4i6tDtbF5KXQPLrvKdh3GXDfenUMXzUwJWPINJPOBhD563DYFzMN7kwPZEJ4stWsyUvK/RICporcHxkFtv45IA8KERkZ84VsD4YANOuuiI4zGsf0+PVQxOU248JFLCOclkvKCvN2XKSWZIVmZwTxLfKC6fa9LnwoWdf8SVxnXYKoY4CMe78D3rmTTZ+eCDfJPAwQYGrBAJwLKuFO5ovtmgeDKQ6NDXircBT359Bxb2fKYVLCwROZrSBUzLo3ryUBGR987rlkDKwaR2hBBCrgC4CRFCCLEMbkKEEEIsg5sQIYQQy+AmRAghxDJmrTquZdmIOAPT1SKDY7WwbGOdrggZHsJlvRPYKiffjuU9qxfqCjH/Mmyvka/g4VwWxKqSiuE7wERRV9V8wo8Tz50rYdseN/R5EQmCpHYm5dkGD7b0GDUohPaWsFxrWbPe/3f6dFsQEZH3KrqqTUQkH8FqpYpB8fZaskuLHRrGiQ5TWaxKGuuph3FXk66Oq7bhuWwJGGyIlmRh/Gg3TngWX66ru0ohg+ryOF6HriRu48mRiBYr5gwGNXl8/xhyDkoJC8Swss9mSIRmlOrhi4a6gcIS+QSJiH8Uj2FqPi7vKBgUoH59bB1Fg5KujOtQpv4bwjUX9Ht8cAzbLQ2O4/hf9X4Kxh0ZvT9VF+5PYFgvWylc/vsN34QIIYRYBjchQgghlsFNiBBCiGVwEyKEEGIZM96ELly4IH/4h38oDQ0N4vf75brrrpPDhw9Pfa6Ukm3btklra6v4fD655ZZb5NixYx9powkhhMwNZqSOm5yclJtuukk+9alPyU9+8hNpbm6Wc+fOSW1t7VSZJ554Qp588kn53ve+J0uWLJFvf/vbcvvtt8upU6ckGAxe9rVW1cXEXTNdoTI4js2vCiCpXW0jyEYnIumxOhi3GbyOxnK6vGdBEKvjTCq4/7v+IIxnDJmfUlVdCWVSgR3LYZWZx+Dv9lpKV429MqjHRES+ueSnMD5QwqqxCeBBJiISz+vKHNN45yawiuf7sRthPFHE5S9M6mslP4ilWp5xrLJyrcBryOHQ/cbeGsTzkB/C17SV8Xw6CzheCutKKEcYr8OyH68rt24bKCIiqQt6UkPlMSSFTOGx8o3idicX43qqoP5gN67bP2byd4NhccX0jtYGDIrBOFbFuupxeX93HMbTS/TnSiaC+9M0iP0R840mRZ4hAWJIr989DotKaT5eKw43VtHa4vp9VfHjdpTBLVgxKPoQM9qEvvvd70pbW5s8++yzU7GOjo6p/1ZKyc6dO+Wxxx6Tu+66S0RE9uzZI5FIRJ5//nm57777ZnI5Qgghc5wZ/TruxRdflPXr18vnP/95aW5uljVr1sgzzzwz9XlPT4/EYjHZsmXLVMzj8cjmzZvl4EH8NlAoFCSZTE77IYQQcnUwo02ou7tbdu3aJV1dXfLSSy/J/fffL1/72tfkueeeExGRWCwmIiKRyPQ/fotEIlOfXcqOHTskHA5P/bS1tX2QfhBCCLkCmdEmVK1WZe3atbJ9+3ZZs2aN3HffffIf/sN/kF27dk0rZ7vkL3+VUlrsfbZu3SqJRGLqZ2BgYIZdIIQQcqUyo02opaVFVqyYnqRr+fLl0t/fLyIi0WhURER76xkZGdHejt7H4/FIKBSa9kMIIeTqYEbChJtuuklOnTo1LXb69Glpb28XEZHOzk6JRqOyf/9+WbNmjYiIFItFOXDggHz3u9+dUcN+OdgpDv90T69qEatNksO1WqxtJf71X6YdZxhsqMnDeEdoQouZPOLeTWDfr2dtG2F8gQdLWapKf2vs8uD+pMvY96zOi/v56thiLeZxYiVdyWAIFnVimVWpisuHPfrYOuqx0ibpw/5zS2pw5tJ4GSvyzvbpX3pMgp1inUHBNYnb4q7T+1MB2WNFxPg1z25QwfljOO7o1esv1eC++4ex8tDk49ZwBGQ5zeKGFw3fEX1jWGXlNNSj7Po1c824bpM6LNmG78PiTVG9jtLlZ2EVESl78DwUo5ev8LXhZksphLO8jl6Hr1nxGhZRs74Oqxk8JqFa7FWYNfgmSjsonzVlmwWxy0+sOrNN6D/+x/8omzZtku3bt8sXvvAFeeONN2T37t2ye/fuixe22eThhx+W7du3S1dXl3R1dcn27dvF7/fL3XffPZNLEUIIuQqY0SZ0/fXXywsvvCBbt26VP/mTP5HOzk7ZuXOn3HPPPVNlHnnkEcnlcvLAAw/I5OSkbNiwQfbt2zejvxEihBBydTDjVA6f/exn5bOf/azxc5vNJtu2bZNt27Z9mHYRQgi5CqB3HCGEEMuYtUntcv1BsXunHwwHBvGeCfK0SWoxPvxrrcd/DDuewYe8r727RIs1/Qs+hE4vwAeLpwIdMF4J4JNLV7Nu69FSh9s9kcW2NQ7DyWB8Qj+ddnrwofL3vdgqB9nwiIgMnsInyypU0oMFPIaONJ7jF47cDOMmtUEYaD7cSTwmpkNrewlXnmvUx7AUNNjwYOcfsRkStbmTeE1ko/q4FOtwHZ44vmbFcNjuSejXtJcNY1I0jEkDnreqC5ePr9TFMI1tcVh2rNAI4ybbnnhE748rjdthL+HnRD6CxTqFOixWETBc+SY8hk5DwsBSA76mGCyunHY97mvCAoSgF9sTpZL4XlZlfXDtScN2gZo3A2EC34QIIYRYBjchQgghlsFNiBBCiGVwEyKEEGIZ3IQIIYRYxqxVx1VDZRHfdLVIzmCX48wCC5D3GmDZiUasQGlqjcN4qV5XqsWX6UnARMToVaGcOO4bxAoxG0gyNuLE13QZ1Fd5kwVfVO+/msBqnbNnOmG8bFD1qXqDugdkuHLGcd9rzmMVUxU3UXLNBosaoFazGTJtFQyqMd8I7mfNkK4mzBospUB+QhERcWCxkpR9uC3ecaCEwk5GRsWg3aACRAo2k2LQP4bn2DuCba8qhgR79pKuMnP/HCecbHoHJ4ushrGiNduqK75caawALdTh9vleBopOEXH347ZkluvK0FQO140si0REas4aVHNBPBcVt14+E8YLLmPDnk12k61SCMzzDBRvM4FvQoQQQiyDmxAhhBDL4CZECCHEMrgJEUIIsYxZJ0xQ/9vOpJrTDzptedzcSl4/6FP4HFKqOXywWsnik+IKcMFQhnaYDoSrBmFCpYC/AyB9Q9XQH7vhgLtiiKP+2/K4HRVDvOow5N8xjK2A4tU87lDFYAtTNeRmqeZNY6vXUwH2Tobm/e/y+JNySY9XTMIEQ91iaIvJikaBobUZ1oRpHYI0VReLgyG0gT6KiIghXq4YhAllwz0L+o/G9WLdeDFXK3iwysBuyVbGg1Uu4faVy3iC7FXclnIJ5Jgq4rpthrlHa1ZEpOIyCErQfeU2LApTMi3TPe4CC870/AXPsWrh4ngogz3VtKapyyn1f5Dz589LW1ub1c0ghBDyIRkYGJD58+f/1jKzbhOqVqsyODgowWBQUqmUtLW1ycDAwJxO+51MJtnPOcTV0M+roY8i7OcHRSklqVRKWltbxW7/7ac+s+7XcXa7fWrntNkuvkOGQqE5vQDeh/2cW1wN/bwa+ijCfn4QwuHwZZWjMIEQQohlcBMihBBiGbN6E/J4PPKtb31LPB6P1U35WGE/5xZXQz+vhj6KsJ//J5h1wgRCCCFXD7P6TYgQQsjchpsQIYQQy+AmRAghxDK4CRFCCLEMbkKEEEIsY1ZvQn/5l38pnZ2d4vV6Zd26dfKLX/zC6iZ9KF599VX53Oc+J62trWKz2eQf/uEfpn2ulJJt27ZJa2ur+Hw+ueWWW+TYsWPWNPYDsmPHDrn++uslGAxKc3Oz3HnnnXLq1KlpZeZCP3ft2iXXXnvt1F+Yb9y4UX7yk59MfT4X+ngpO3bsEJvNJg8//PBUbC70c9u2bWKz2ab9RKPRqc/nQh/f58KFC/KHf/iH0tDQIH6/X6677jo5fPjw1OeW9FXNUvbu3atcLpd65pln1PHjx9VDDz2kAoGA6uvrs7ppH5gf//jH6rHHHlM/+MEPlIioF154Ydrn3/nOd1QwGFQ/+MEP1NGjR9UXv/hF1dLSopLJpDUN/gD8zu/8jnr22WfVe++9p44cOaI+85nPqAULFqh0Oj1VZi7088UXX1Q/+tGP1KlTp9SpU6fUo48+qlwul3rvvfeUUnOjj7/JG2+8oTo6OtS1116rHnrooan4XOjnt771LbVy5Uo1NDQ09TMyMjL1+Vzoo1JKTUxMqPb2dvVHf/RH6le/+pXq6elR//zP/6zOnj07VcaKvs7aTeiGG25Q999//7TYsmXL1De/+U2LWvTRcukmVK1WVTQaVd/5znemYvl8XoXDYfVXf/VXFrTwo2FkZESJiDpw4IBSau72Uyml6urq1F//9V/PuT6mUinV1dWl9u/frzZv3jy1Cc2Vfn7rW99Sq1evhp/NlT4qpdQ3vvENdfPNNxs/t6qvs/LXccViUQ4fPixbtmyZFt+yZYscPHjQolZ9vPT09EgsFpvWZ4/HI5s3b76i+5xIJEREpL6+XkTmZj8rlYrs3btXMpmMbNy4cc718cEHH5TPfOYzctttt02Lz6V+njlzRlpbW6Wzs1O+9KUvSXd3t4jMrT6++OKLsn79evn85z8vzc3NsmbNGnnmmWemPreqr7NyExobG5NKpSKRSGRaPBKJSCwWs6hVHy/v92su9VkpJV//+tfl5ptvllWrVonI3Orn0aNHpaamRjwej9x///3ywgsvyIoVK+ZUH/fu3StvvfWW7NixQ/tsrvRzw4YN8txzz8lLL70kzzzzjMRiMdm0aZOMj4/PmT6KiHR3d8uuXbukq6tLXnrpJbn//vvla1/7mjz33HMiYt18zrpUDr/J+6kc3kcppcXmGnOpz1/96lfl3XfflV/+8pfaZ3Ohn0uXLpUjR45IPB6XH/zgB3LvvffKgQMHpj6/0vs4MDAgDz30kOzbt0+8Xq+x3JXezzvuuGPqv6+55hrZuHGjLFq0SPbs2SM33nijiFz5fRS5mKtt/fr1sn37dhERWbNmjRw7dkx27dol/+7f/bupcv+n+zor34QaGxvF4XBou+/IyIi2S88V3lfjzJU+//Ef/7G8+OKL8vLLL0/LrDiX+ul2u2Xx4sWyfv162bFjh6xevVr+/M//fM708fDhwzIyMiLr1q0Tp9MpTqdTDhw4IH/xF38hTqdzqi9Xej8vJRAIyDXXXCNnzpyZM3MpItLS0iIrVqyYFlu+fLn09/eLiHX35qzchNxut6xbt072798/Lb5//37ZtGmTRa36eOns7JRoNDqtz8ViUQ4cOHBF9VkpJV/96lflhz/8ofz85z+Xzs7OaZ/PlX4ilFJSKBTmTB9vvfVWOXr0qBw5cmTqZ/369XLPPffIkSNHZOHChXOin5dSKBTkxIkT0tLSMmfmUkTkpptu0v5c4vTp09Le3i4iFt6bH5vk4UPyvkT7b/7mb9Tx48fVww8/rAKBgOrt7bW6aR+YVCql3n77bfX2228rEVFPPvmkevvtt6dk59/5zndUOBxWP/zhD9XRo0fVH/zBH1xxUtCvfOUrKhwOq1deeWWa5DWbzU6VmQv93Lp1q3r11VdVT0+Pevfdd9Wjjz6q7Ha72rdvn1JqbvQR8ZvqOKXmRj//03/6T+qVV15R3d3d6vXXX1ef/exnVTAYnHrWzIU+KnVRZu90OtWf/umfqjNnzqi//du/VX6/X33/+9+fKmNFX2ftJqSUUk8//bRqb29XbrdbrV27dkrme6Xy8ssvKxHRfu69916l1EWJ5Le+9S0VjUaVx+NRn/zkJ9XRo0etbfQMQf0TEfXss89OlZkL/fz3//7fT63NpqYmdeutt05tQErNjT4iLt2E5kI/3/9bGJfLpVpbW9Vdd92ljh07NvX5XOjj+/zTP/2TWrVqlfJ4PGrZsmVq9+7d0z63oq/MJ0QIIcQyZuWZECGEkKsDbkKEEEIsg5sQIYQQy+AmRAghxDK4CRFCCLEMbkKEEEIsg5sQIYQQy+AmRAghxDK4CRFCCLEMbkKEEEIsg5sQIYQQy/j/ATMkXJbSXxn/AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "noise = tf.random.normal([1, latent_dim])\n",
        "generated_image = generator(noise, training=True)\n",
        "plt.imshow(generated_image[0, :, :, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create discriminator\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then define the discriminator model, again adapted adapted from [here](https://github.com/Kaustubh1Verma/Art-using-GANs/blob/ff41eeb5099d2aa3976ed1f051596d14015548d5/DCGAN/DCGAN.py).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_67 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " leaky_re_lu_25 (LeakyReLU)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " zero_padding2d_5 (ZeroPaddi  (None, 17, 17, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " leaky_re_lu_26 (LeakyReLU)  (None, 17, 17, 64)        0         \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 17, 17, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_52 (Bat  (None, 17, 17, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_27 (LeakyReLU)  (None, 9, 9, 128)         0         \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 9, 9, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_53 (Bat  (None, 9, 9, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 9, 9, 256)         295168    \n",
            "                                                                 \n",
            " leaky_re_lu_28 (LeakyReLU)  (None, 9, 9, 256)         0         \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 9, 9, 256)         0         \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 9, 9, 512)         1180160   \n",
            "                                                                 \n",
            " leaky_re_lu_29 (LeakyReLU)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 41472)             0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 41473     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,610,817\n",
            "Trainable params: 1,610,433\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=kernel_size, strides=2, input_shape=image_shape, padding=\"same\", kernel_initializer=init()))  # 192x256 -> 96x128\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=kernel_size, strides=2, padding=\"same\", kernel_initializer=init()))  # 96x128 -> 48x64\n",
        "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=kernel_size, strides=2, padding=\"same\", kernel_initializer=init()))  # 48x64 -> 24x32\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=kernel_size, strides=1, padding=\"same\", kernel_initializer=init()))  # 24x32 -> 12x16\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(512, kernel_size=kernel_size, strides=1, padding=\"same\", kernel_initializer=init()))  # 12x16 -> 6x8\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=image_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n",
        "discriminator = build_discriminator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let&rsquo;s see what the discriminator thinks of our generated image:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.49969378]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Override `train_step`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tensorflow and Keras offer many ways to combine the generator and discriminator into a GAN model and train it. Here we define a custom model class that overrides the `train_step` method, and define a custom loss function for the discriminator that adds smoothing to improve the convergence of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "class DCGAN(keras.Model):\n",
        "    def __init__(self, generator, discriminator):\n",
        "        super().__init__()\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "\n",
        "\n",
        "    def generator_loss(self,fake_output):\n",
        "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "\n",
        "    # smooth parameter is used to induce one sided label smoothing. It can be tuned accordingly\n",
        "    def discriminator_loss(self,real_output, fake_output):\n",
        "        # This version adds noise as suggested in the official Keras DCGAN example\n",
        "        noise_amt = 0.01\n",
        "        real_loss = cross_entropy(tf.ones_like(real_output)+tf.random.uniform(tf.shape(real_output))*noise_amt,\n",
        "                                  real_output)\n",
        "        fake_loss = cross_entropy(tf.zeros_like(fake_output)+tf.random.uniform(tf.shape(fake_output))*noise_amt,\n",
        "                                  fake_output)\n",
        "\n",
        "        # This version adds one sided smoothing\n",
        "        # label for real image is (1-smooth)\n",
        "        # smooth = 0.01\n",
        "        # real_loss = cross_entropy(tf.ones_like(real_output)*(1-smooth), real_output)\n",
        "        # fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "        # This version does the usual loss\n",
        "        # real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "        # fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    def compile(self,generator_optimizer,discriminator_optimizer):\n",
        "        super().compile()\n",
        "        self.generator_optimizer = generator_optimizer\n",
        "        self.discriminator_optimizer = discriminator_optimizer\n",
        "\n",
        "    @tf.function # This improves performance\n",
        "    def train_step(self,data):\n",
        "        # Standard procedure to recover batch size\n",
        "        batch_size = tf.shape(data)[0]\n",
        "\n",
        "        # feed a random input to generator\n",
        "        seed = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            # generate image using generator\n",
        "            generated_image = self.generator(seed, training=True)\n",
        "            # discriminator's prediction for real image\n",
        "            real_output = self.discriminator(data, training=True)\n",
        "\n",
        "            # discriminator's estimate for fake image\n",
        "            fake_output = self.discriminator(generated_image, training=True)\n",
        "\n",
        "            # compute loss\n",
        "            gen_loss = self.generator_loss(fake_output)\n",
        "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
        "\n",
        "            # optimize generator first\n",
        "            generator_grad = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "            discriminator_grad = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "            # optimize discriminator after generator\n",
        "            self.generator_optimizer.apply_gradients(zip(generator_grad,\n",
        "                                                         self.generator.trainable_variables))\n",
        "            self.discriminator_optimizer.apply_gradients(zip(discriminator_grad,\n",
        "                                                             self.discriminator.trainable_variables))\n",
        "\n",
        "        return {\n",
        "            \"generator loss\": gen_loss,\n",
        "            \"discriminator_loss\": disc_loss\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create callback that periodically saves generated images\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to visualize the results every epoch and save the resulting model and this Python class will take care of that automatically. The images and models will be saved in a specified directory. Periodically check the directory to see how the results change at each epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img, latent_dim, path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        self.path = path\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        #generated_images *= 255\n",
        "        generated_images = generated_images * 127.5 + 127.5 #255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save(os.path.join(self.path, \"e%03d_generated_img_%d.png\" % (epoch+1, i)))\n",
        "        print('Saving epoch %d to %s'%(epoch+1, self.path))\n",
        "        self.model.save_weights(os.path.join(self.path, \"e%0d_weights\"%(epoch+1)))\n",
        "        self.model.generator.save(os.path.join(self.path, \"e%0d_generator.hd5\"%(epoch+1)), save_format='h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the end to end model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally let&rsquo;s define the optimizers for the generator and discriminator (the Adam optimizer is usually recommended), compile the model and run our training procedure.\n",
        "Change the value of `model_path` to change where the models and results will be saved. Here we train for `30` epochs. Depending on the size of the training set, less or more epochs may be desired. Adjust this by changing the value of the `epochs` variable below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.0191 - discriminator_loss: 1.0932Saving epoch 1 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 1.1007 - discriminator_loss: 1.0954\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.4588 - discriminator_loss: 0.8262Saving epoch 2 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 9s 1s/step - generator loss: 1.5239 - discriminator_loss: 0.7810\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.7207 - discriminator_loss: 0.6839Saving epoch 3 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 9s 1s/step - generator loss: 1.7814 - discriminator_loss: 0.6781\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.5955 - discriminator_loss: 0.7511Saving epoch 4 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 9s 1s/step - generator loss: 1.5992 - discriminator_loss: 0.7186\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.6841 - discriminator_loss: 0.8078Saving epoch 5 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 9s 1s/step - generator loss: 1.5847 - discriminator_loss: 0.8240\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.9558 - discriminator_loss: 0.5359Saving epoch 6 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 1.9545 - discriminator_loss: 0.5152\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.9863 - discriminator_loss: 0.7388Saving epoch 7 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 1.8993 - discriminator_loss: 0.7165\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.0505 - discriminator_loss: 0.7356Saving epoch 8 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 1.9823 - discriminator_loss: 0.7096\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.9697 - discriminator_loss: 0.7804Saving epoch 9 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 1.9150 - discriminator_loss: 0.7219\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.8564 - discriminator_loss: 0.7183Saving epoch 10 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 1.8828 - discriminator_loss: 0.6730\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.0088 - discriminator_loss: 0.4855Saving epoch 11 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 1.9475 - discriminator_loss: 0.4714\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.4140 - discriminator_loss: 0.5956Saving epoch 12 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 2.3580 - discriminator_loss: 0.5729\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.6786 - discriminator_loss: 0.5637Saving epoch 13 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 2.6056 - discriminator_loss: 0.5319\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.3060 - discriminator_loss: 0.5738Saving epoch 14 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 2.2951 - discriminator_loss: 0.5364\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.6101 - discriminator_loss: 0.7168Saving epoch 15 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 2.5944 - discriminator_loss: 0.7114\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.2314 - discriminator_loss: 0.7802Saving epoch 16 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 2.1699 - discriminator_loss: 0.7807\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.2242 - discriminator_loss: 1.0903Saving epoch 17 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 2.1765 - discriminator_loss: 1.1112\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.9913 - discriminator_loss: 0.8409Saving epoch 18 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 2.0557 - discriminator_loss: 0.8156\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.5120 - discriminator_loss: 1.1963Saving epoch 19 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 2s/step - generator loss: 1.4744 - discriminator_loss: 1.2576\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.7772 - discriminator_loss: 0.7665Saving epoch 20 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 1.8267 - discriminator_loss: 0.7414\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.9370 - discriminator_loss: 0.6867Saving epoch 21 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 1.9884 - discriminator_loss: 0.6419\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.7611 - discriminator_loss: 0.9060Saving epoch 22 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 1.7655 - discriminator_loss: 0.8881\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.1137 - discriminator_loss: 0.6608Saving epoch 23 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 10s 1s/step - generator loss: 2.0064 - discriminator_loss: 0.6744\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.9577 - discriminator_loss: 0.9081Saving epoch 24 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 2s/step - generator loss: 1.9957 - discriminator_loss: 0.8746\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.7792 - discriminator_loss: 0.9201Saving epoch 25 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 1.7188 - discriminator_loss: 0.9412\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.0972 - discriminator_loss: 0.5534Saving epoch 26 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 2.1274 - discriminator_loss: 0.5023\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 2.3480 - discriminator_loss: 0.8657Saving epoch 27 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 2s/step - generator loss: 2.4151 - discriminator_loss: 0.8498\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.9280 - discriminator_loss: 0.8401Saving epoch 28 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 12s 2s/step - generator loss: 1.9711 - discriminator_loss: 0.8584\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.9168 - discriminator_loss: 0.6928Saving epoch 29 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 13s 2s/step - generator loss: 1.8985 - discriminator_loss: 0.7029\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - ETA: 0s - generator loss: 1.5666 - discriminator_loss: 0.8806Saving epoch 30 to ./models/dcgan_dmlap\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "7/7 [==============================] - 11s 1s/step - generator loss: 1.6025 - discriminator_loss: 0.8478\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2b87077c0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = './models/dcgan_dmlap'\n",
        "epochs = 30\n",
        "\n",
        "generator_optimizer = Adam(learning_rate=0.0002,beta_1=0.5)\n",
        "discriminator_optimizer = Adam(learning_rate=0.0002,beta_1=0.5)\n",
        "\n",
        "gan = DCGAN(generator, discriminator)\n",
        "gan.compile(generator_optimizer,discriminator_optimizer)\n",
        "\n",
        "\n",
        "gan.fit(\n",
        "    dataset, epochs=epochs,\n",
        "    callbacks=[GANMonitor(num_img=5,\n",
        "                          latent_dim=latent_dim,\n",
        "                          path=model_path)]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An alternative training procedure..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Epoch 1 - 7 of 7 [D loss: 0.24498585611581802 | D Accuracy: 0.0] [G loss: 0.6724389791488647]Saving epoch 1 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e1_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e1_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2\n",
            "Epoch 2 - 7 of 7 [D loss: 0.6575204432010651 | D Accuracy: 0.0] [G loss: 2.201547145843506]Saving epoch 2 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e2_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e2_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3\n",
            "Epoch 3 - 7 of 7 [D loss: 0.19274292141199112 | D Accuracy: 0.0] [G loss: 1.496854305267334]Saving epoch 3 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e3_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e3_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4\n",
            "Epoch 4 - 7 of 7 [D loss: 0.5358227789402008 | D Accuracy: 0.0] [G loss: 1.4070091247558594]Saving epoch 4 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e4_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e4_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5\n",
            "Epoch 5 - 7 of 7 [D loss: 0.33495670557022095 | D Accuracy: 0.0] [G loss: 0.9495002031326294]Saving epoch 5 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e5_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e5_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6\n",
            "Epoch 6 - 7 of 7 [D loss: 0.15428443951532245 | D Accuracy: 0.0] [G loss: 0.6588655710220337]Saving epoch 6 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e6_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e6_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7\n",
            "Epoch 7 - 7 of 7 [D loss: 0.04323802958242595 | D Accuracy: 0.0] [G loss: 1.0922564268112183]Saving epoch 7 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e7_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e7_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8\n",
            "Epoch 8 - 7 of 7 [D loss: 0.10513566806912422 | D Accuracy: 0.0] [G loss: 1.3462297916412354]Saving epoch 8 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e8_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e8_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9\n",
            "Epoch 9 - 7 of 7 [D loss: 0.033341895788908005 | D Accuracy: 0.0] [G loss: 1.0952402353286743]Saving epoch 9 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e9_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e9_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10\n",
            "Epoch 10 - 7 of 7 [D loss: 0.04201117530465126 | D Accuracy: 0.0] [G loss: 1.9005893468856812]Saving epoch 10 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e10_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e10_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11\n",
            "Epoch 11 - 7 of 7 [D loss: 0.006760184653103352 | D Accuracy: 0.0] [G loss: 1.3467893600463867]Saving epoch 11 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e11_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e11_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12\n",
            "Epoch 12 - 7 of 7 [D loss: 1.4705643840134144 | D Accuracy: 0.0] [G loss: 4.389289379119873]Saving epoch 12 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e12_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e12_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13\n",
            "Epoch 13 - 7 of 7 [D loss: 0.03624699683859944 | D Accuracy: 0.0] [G loss: 1.4036837816238403]Saving epoch 13 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e13_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e13_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14\n",
            "Epoch 14 - 7 of 7 [D loss: 0.26195386052131653 | D Accuracy: 0.0] [G loss: 1.1488912105560303]Saving epoch 14 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e14_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e14_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15\n",
            "Epoch 15 - 7 of 7 [D loss: 2.944468855857849 | D Accuracy: 0.0] [G loss: 0.6948286294937134]Saving epoch 15 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e15_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e15_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16\n",
            "Epoch 16 - 7 of 7 [D loss: 0.077696543186903 | D Accuracy: 0.0] [G loss: 3.491215705871582]Saving epoch 16 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e16_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e16_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17\n",
            "Epoch 17 - 7 of 7 [D loss: 0.1663377285003662 | D Accuracy: 0.0] [G loss: 1.0753763914108276]Saving epoch 17 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e17_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e17_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18\n",
            "Epoch 18 - 7 of 7 [D loss: 0.3867080360651016 | D Accuracy: 0.0] [G loss: 1.002825140953064]Saving epoch 18 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e18_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e18_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19\n",
            "Epoch 19 - 7 of 7 [D loss: 0.04738122224807739 | D Accuracy: 0.0] [G loss: 0.5354114770889282]Saving epoch 19 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e19_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e19_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20\n",
            "Epoch 20 - 7 of 7 [D loss: 0.01495237648487091 | D Accuracy: 0.0] [G loss: 1.1895887851715088]Saving epoch 20 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e20_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e20_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21\n",
            "Epoch 21 - 7 of 7 [D loss: 0.06144413538277149 | D Accuracy: 0.0] [G loss: 0.34459587931632996]Saving epoch 21 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e21_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e21_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22\n",
            "Epoch 22 - 7 of 7 [D loss: 0.011027229949831963 | D Accuracy: 0.0] [G loss: 1.6828444004058838]Saving epoch 22 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e22_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e22_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23\n",
            "Epoch 23 - 7 of 7 [D loss: 5.759896516799927 | D Accuracy: 0.0] [G loss: 0.869853675365448]Saving epoch 23 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e23_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e23_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24\n",
            "Epoch 24 - 7 of 7 [D loss: 0.3464338034391403 | D Accuracy: 0.0] [G loss: 0.5862081050872803]Saving epoch 24 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e24_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e24_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25\n",
            "Epoch 25 - 7 of 7 [D loss: 0.026240582577884197 | D Accuracy: 0.0] [G loss: 0.2963801622390747]Saving epoch 25 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e25_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e25_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26\n",
            "Epoch 26 - 7 of 7 [D loss: -0.030753755941987038 | D Accuracy: 0.0] [G loss: 0.09943316876888275]Saving epoch 26 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e26_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e26_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27\n",
            "Epoch 27 - 7 of 7 [D loss: -0.0015431605279445648 | D Accuracy: 0.0] [G loss: 0.02085435390472412]Saving epoch 27 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e27_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e27_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28\n",
            "Epoch 28 - 7 of 7 [D loss: -0.02987215295433998 | D Accuracy: 0.0] [G loss: 0.04696935415267944]Saving epoch 28 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e28_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e28_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29\n",
            "Epoch 29 - 7 of 7 [D loss: 0.008268848061561584 | D Accuracy: 0.0] [G loss: 0.015474828891456127]Saving epoch 29 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e29_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e29_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30\n",
            "Epoch 30 - 7 of 7 [D loss: -0.032565606757998466 | D Accuracy: 0.0] [G loss: 0.03992844745516777]Saving epoch 30 to ./models/dcgan_dmlap_2\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e30_generator.hd5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./models/dcgan_dmlap_2/e30_generator.hd5/assets\n"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.legacy.Adam(0.0001, 0.5, decay=0.00005)\n",
        "\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# The generator takes noise as input and generates imgs\n",
        "z = Input(shape=(latent_dim,))\n",
        "img = generator(z)\n",
        "\n",
        "# For the combined model we will only train the generator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# The discriminator takes generated images as input and determines validity\n",
        "valid = discriminator(img)\n",
        "\n",
        "# The combined model  (stacked generator and discriminator)\n",
        "# Trains the generator to fool the discriminator\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "#%%\n",
        "\n",
        "epochs = 30 #50\n",
        "save_interval = 1\n",
        "\n",
        "model_path = \"./models/dcgan_dmlap\"\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "import sys\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    n = dataset.cardinality() # The number of batches per epoch\n",
        "    print(\"Epoch %d\"%(epoch+1))\n",
        "    # Iterate over all batches\n",
        "    for i, batch in enumerate(dataset.as_numpy_iterator()):\n",
        "        # Convert batch to numpy for convenience\n",
        "        half_batch_size = len(batch)//2\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "        # Get random half of the batch\n",
        "        idx = np.random.randint(0, batch.shape[0], half_batch_size)\n",
        "        imgs = batch[idx]\n",
        "        # For the remaining half batch, sample noise and generate new images\n",
        "        noise = np.random.normal(0, 1, (half_batch_size, 100))\n",
        "        gen_imgs = generator.predict(noise, verbose=0)\n",
        "\n",
        "        # Train the discriminator (real classified as ones and generated as zeros)\n",
        "        real_labels = np.ones((half_batch_size, 1))\n",
        "        fake_labels = np.zeros((half_batch_size, 1))\n",
        "        noise_amt = 0.01\n",
        "        real_labels += tf.random.uniform(tf.shape(real_labels))*noise_amt\n",
        "        fake_labels += tf.random.uniform(tf.shape(fake_labels))*noise_amt\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, real_labels)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake_labels)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Print progress on same line\n",
        "        sys.stdout.write(\"\\r\" + \"Epoch %d - %d of %d \"%(epoch+1, i+1, n) + \"[D loss: \"+str(d_loss[0])+\" | D Accuracy: \"+str(100 * d_loss[1])+\"] [G loss: \"+str(g_loss)+\"]\")\n",
        "\n",
        "    if epoch % save_interval == 0:\n",
        "        print('Saving epoch %d to %s'%(epoch+1, model_path))\n",
        "        num_examples = 5\n",
        "        random_latent_vectors = tf.random.normal(shape=(num_examples, latent_dim))\n",
        "        generated_images = generator(random_latent_vectors, training=False)\n",
        "        #generated_images *= 255\n",
        "        generated_images = generated_images * 127.5 + 127.5 #255\n",
        "        generated_images.numpy()\n",
        "        for i in range(num_examples):\n",
        "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save(os.path.join(model_path, \"e%03d_generated_img_%d.png\" % (epoch+1, i)))\n",
        "\n",
        "        generator.save(os.path.join(model_path, \"e%0d_generator.hd5\"%(epoch+1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "org": null,
    "vscode": {
      "interpreter": {
        "hash": "1c544d3133b9d8c6f36fca025551af31afa9ef134259e7064ad6be0c15e6401c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
